\documentclass[a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath,amsthm}
\usepackage{amssymb,amsfonts}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage[obeyspaces]{url}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\usepackage{color}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{skull}
\usepackage{stackengine}
\usepackage{scalerel}
\usepackage{mathrsfs}
\usepackage{wasysym}
\usepackage{tikz}
\usepackage{relsize}
\usepackage{cancel}
\usepackage{fontawesome}
\usepackage[font=small]{caption}
\colorlet{shadecolor}{blue!9}
\definecolor{Red}{rgb}{0,0,0.3}

\setlength{\headheight}{14pt}
\setlength{\topmargin}{-1cm}
\setlength{\evensidemargin}{-1cm}
\setlength{\oddsidemargin}{-1cm}
\setlength{\textwidth}{18cm} 
\setlength{\textheight}{25cm}

\linespread{1.2}

\usepackage{lastpage}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{} % clear all header fields
\fancyhead[RE]{\slshape \rightmark}
\fancyhead[LO]{\slshape \leftmark}
%\fancyhead[CO,CE]{\bfseries Jacopo D'Aurizio - Esercizi svolti di Analisi 1}
\fancyfoot{} % clear all footer fields
\fancyfoot[CE,CO]{Pagina \thepage\ / \pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.2pt}
\renewcommand{\epsilon}{\varepsilon}

%\renewcommand{\thesubsection}{\Roman{subsection}}
\newcommand{\mydef}{\;\dot{=}_{\!\!\!\!\mbox{. }}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\bigo}[1]{O\left(#1\right)}
\newcommand{\smallo}[1]{o\left(#1\right)}
\newcommand{\hard}{(\skull)}
\newcommand{\Conv}[1]{\operatorname{Hull}\left(#1\right)}
\newcommand{\arcsinh}[1]{\operatorname{arcsinh}\left(#1\right)}
\newcommand{\arccosh}[1]{\operatorname{arccosh}\left(#1\right)}
\newcommand{\arctanh}[1]{\operatorname{arctanh}\left(#1\right)}
\newcommand{\emptyline}{$\phantom{}$}
\newcommand{\nline}{$\phantom{}$\\}
\newcommand{\sinc}{\operatorname{sinc}}
\newcommand{\GM}{\operatorname{GM}}
\newcommand{\AM}{\operatorname{AM}}
\renewcommand{\gcd}{\operatorname{mcd}}
\newcommand{\mcd}{\operatorname{mcd}}

\theoremstyle{definition}
\newtheorem{theorem}{\color{Red}\underline{\textrm Teorema}}

\newenvironment{theo}
  {\begin{shaded}\begin{theorem}}
  {\end{theorem}\end{shaded}}

%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{cor}[theorem]{Corollario}
%\newtheorem{definizione}[theorem]{Definizione}
%\newtheorem{esempio}[theorem]{Esempio}
%\newtheorem{ex}[theorem]{Esercizio}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollario}
\newtheorem{definizione}[theorem]{Definizione}
\newtheorem{esempio}[theorem]{Esempio}
\newtheorem{ex}[theorem]{Esercizio}
\newtheorem{oss}{\underline{\textrm Osservazione}}
\numberwithin{theorem}{section}

\makeatletter
\DeclareFontFamily{U}{tipa}{}
\DeclareFontShape{U}{tipa}{m}{n}{<->tipa10}{}
\newcommand{\arc@char}{{\usefont{U}{tipa}{m}{n}\symbol{62}}}%

\newcommand{\arc}[1]{\mathpalette\arc@arc{#1}}

\newcommand\dangersign[1][2ex]{%
  \renewcommand\stacktype{L}%
  \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny !}}{#1}%
}

\newcommand{\arc@arc}[2]{%
  \sbox0{$\m@th#1#2$}%
  \vbox{
    \hbox{\resizebox{\wd0}{\height}{\arc@char}}
    \nointerlineskip
    \box0
  }%
}
\makeatother
\setcounter{section}{0}
\begin{document}
\setlength\parindent{0pt}
\thispagestyle{empty}
\begin{center}{\large \textbf{ {\Huge Calculus 101 for Jackchans} \\
B.A.M. \& Jack, 2023}}
\end{center}
\rule{\textwidth}{1pt}
\tableofcontents

\section{Sproloquio Introduttivo}
    Queste note hanno lo scopo di essere una raccolta degli esercizi, dei fatti notevoli, dei fatti meno notevoli ma altrettando interessanti appresi, grazie a Jack, durante lo studio per l'esame di Analisi 1 presso l'università di Pisa.
    \\
    Per la natura del materiale presente, queste note non saranno da sole (immagino) sufficienti a preparare l'esame in questione, a causa della possibile brevità di alcune sezioni e spiegazioni.
    \\
\section{Definizioni e Richiami}
La serie di Taylor di una funzione $f(x)\in C^{\infty}$, centrata in $x_0$, è definita come:
$$\sum_{n\geq 0}^{}\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n.$$
Se i \emph{coefficienti} $a_n=\frac{f^{(n)}(x_0)}{n!}$ soddisfano definitivamente $|a_n|=O(M^n)$ per qualche $M\in\R^+$, nella palla $|x-x_0|<\frac{1}{M}$ la precedente serie converge puntualmente a $f(x)$, e converge uniformemente su tutti i compatti contenuti nella palla, per confronto con la serie geometrica $\sum_{n\geq 0}M^n z^n = \frac{1}{1-Mz}$. Le serie di Taylor centrate nell'origine sono anche dette serie (o \emph{sviluppi}) di Maclaurin. In termini di quest'ultime, diamo alcune definizioni importanti.
\begin{itemize}
\item La funzione esponenziale può essere definita attraverso $$e^x=\sum_{n\geq 0}\frac{1}{n!}x^n$$ 
e soddisfa l'equazione funzionale $f(x)f(y)=f(x+y)$, nonché l'equazione differenziale $f'(x)=f(x)$\\ con dato iniziale $f(0)=1$.
\item Il seno può essere definito attraverso $$\sin x = \sum_{n\geq 0}\frac{(-1)^{2n+1}}{(2n+1)!}x^{2n+1}$$
ed è soluzione dell'equazione differenziale $f''(x)+f(x)=0$ con dati iniziali $f(0)=0, f'(0)=1$.
\item Il coseno può essere definito attraverso $$\cos x = \sum_{n\geq }\frac{(-1)^n}{(2n)!}x^{2n}$$
ed è soluzione di $f''(x)+f(x)=0$ con dati iniziali $f(0)=1, f'(0)=0$.
\end{itemize}
Le tre serie elencate si estendono impunemente al campo complesso definendo funzioni analitiche e intere (il raggio di convergenza della serie di Taylor, centrata in qualunque punto, è $+\infty$). Con le definizioni adottate è immediato verificare che vale l'\textbf{identità di Eulero-De Moivre} $e^{i\theta}=\cos\theta+i\sin\theta$ per ogni $\theta\in\C$. Restringendosi al caso $\theta\in\R$ si ha che $f(\theta)=e^{i\theta}$ fornisce una parametrizzazione per lunghezza d'arco della circonferenza goniometrica, recuperando così l'usuale definizione ``scolastica'' delle funzioni trigonometriche elementari. Dall'identità di Eulero, considerando la parte reale o la parte immaginaria di $e^{i(\theta+\phi)}=e^{i\theta}\cdot e^{i\phi}$, si ottengono le \textbf{formule di addizione/sottrazione} del seno e del coseno:
$$ \sin(\theta\pm\phi)=\sin\theta\cos\phi \pm \cos\theta\sin\phi $$
$$ \cos(\theta\pm\phi)=\cos\theta\cos\phi \mp \sin\theta\sin\phi $$
e dal caso $\theta=\phi$ si ottengono le \textbf{formule di duplicazione/bisezione}:
$$ \sin(2\theta) = 2\sin\theta\cos\theta $$
$$ \cos(2\theta) = \cos^2\theta-\sin^2\theta = 2\cos^2\theta - 1 = 1-2\sin^2\theta $$
$$ \cos\frac{\theta}{2}=\pm\sqrt{\frac{1+\cos\theta}{2}},\qquad \sin\frac{\theta}{2}=\pm\sqrt{\frac{1-\cos\theta}{2}}.$$
Dalle formule di addizione/sottrazione si ottengono altresì le \textbf{formule di prostaferesi}, che permettono di convertire somme di seni o coseni in prodotti di seni o coseni e viceversa:
$$ 2\sin\theta\sin\phi = \cos(\theta-\phi)-\cos(\theta+\phi)\qquad \cos\alpha-\cos\beta = 2\sin\frac{\alpha+\beta}{2}\sin\frac{\beta-\alpha}{2} $$
$$ 2\sin\theta\cos\phi = \sin(\theta+\phi)+\sin(\theta-\phi)\qquad \sin\alpha+\sin\beta = 2\sin\frac{\alpha+\beta}{2}\cos\frac{\alpha-\beta}{2} $$
$$ 2\cos\theta\cos\phi = \cos(\theta+\phi)+\cos(\theta-\phi),\qquad \cos\alpha+\cos\beta = 2\cos\frac{\alpha+\beta}{2}\cos\frac{\alpha-\beta}{2}. $$

\begin{ex} Si dimostri che le somme parziali della successione $\{\sin n\}_{n\geq 1}$ sono limitate e si determini esplicitamente il valore del loro estremo superiore. 
\end{ex}
\textbf{Soluzione}. Posto $A_N=\sum_{n=1}^{N}\sin n$, per le formule di prostaferesi si ha 
$$ 2\sin\tfrac{1}{2}\sum_{n=1}^{N}\sin n = \sum_{n=1}^{N}\left(\cos\left(n-\tfrac{1}{2}\right)-\cos\left(n+\tfrac{1}{2}\right)\right)=\cos\left(\tfrac{1}{2}\right)-\cos\left(N+\tfrac{1}{2}\right) ,$$
$$ A_N = \frac{\cos\left(\tfrac{1}{2}\right)-\cos\left(N+\tfrac{1}{2}\right)}{2\sin\tfrac{1}{2}} $$
e poiché la successione $\{\cos\left(N+\frac{1}{2}\right)\}_{N\geq 0}$ è densa in $[-1,1]$, dalle formule di duplicazione si ha 
$$ \sup_N A_N = \frac{1+\cos\tfrac{1}{2}}{2\sin\tfrac{1}{2}} = \frac{2\cos^2\tfrac{1}{4}}{4\sin\tfrac{1}{4}\cos\tfrac{1}{4}} = {\color{blue}\tfrac{1}{2}\cot\tfrac{1}{4}}<2.$$



\section{Limiti e Continuità}
\subsection{Limiti di Successioni}
Saranno date per buone le definizioni di Spazio Metrico e Topologico.

\begin{definizione}
Una successione $\{a_n\}_{n\in\N}$ si dice: \\
\textit{inferiormente limitata} se  esiste $m$ tale che $\forall n, a_n\geq m$ \\
\textit{superiormente limitata} se  esiste $m$ tale che $\forall n, a_n\leq M$ \\
\textit{limitata} se eistono due numeri $m$ ed $M$ tali che $\forall n, m\leq a_n\leq M$
\end{definizione}

\begin{definizione}
Una successione $\{a_n\}$ si dice convergente se $\exists l\in E$ tale che: $$\forall \epsilon>0,\text{ definitivamente } |a_n-l|<\epsilon$$ \\
$l$ si chiama \textbf{limite della successione $a_n$}:
$$\lim_{n\to+\infty}a_n=l.$$
\end{definizione}

\textbf{Nota}: l'operatore $\lim$ è \textbf{lineare}.

\textbf{Definizione}
Una successione $\{a_n\}$ si dice \emph{crescente} se $$\forall n, a_{n+1} > a_n$$
 e si dice \emph{debolmente crescente} se vale la disuguaglianza $a_n\leq a_{n+1}$. È definito analogamente il concetto di decrescenza. Sia le successioni crescenti che quelle decrescenti sono dette monotone.\\
 
 
\begin{theorem}[Monotonia]
Sia $\{a_n\}$ una successione monotona crescente e superiormente limitata.\\ Allora $a_n$ converge e il suo limite è $\sup_{n\in\N} a_n$. Vale l'analogo con l'$\inf$ per le successioni decrescenti.
\end{theorem}
\begin{proof} Senza perdità di generalità dimostriamo il caso delle successioni monotone crescenti e limitate. \\
Poiché $\{a_n\}$ è limitata esiste finito $\Gamma=\sup_{n\in\N}a_n$ e questo realizza $\Gamma \geq a_n$ per ogni $n\in\N$.\\
Per proprietà del $\sup$, in ogni intorno sinistro di $\Gamma$ vi è almeno un elemento della successione, in particolare
$$ \forall \epsilon > 0, \exists n\in \N: \Gamma-\epsilon < a_n \leq \Gamma. $$
Poiché la successione è crescente e limitata da $\Gamma$ ne consegue
$$ \forall \epsilon > 0, \exists n\in \N: \forall m\geq n, \Gamma-\epsilon < a_m \leq \Gamma, $$
e questo dimostra che 
$$\lim_{n\to\infty}a_n = \Gamma.$$
\end{proof}


\begin{theorem}[Permanenza del segno]
Se $a_n \to a$ e $a>0$ allora $a_n>0$ definitivamente.
(vale anche col minore di 0)
\end{theorem}
\begin{proof}
Vale che $$\forall\epsilon>0,\text{ definitivamente }|a_n-a|<\epsilon$$
che è equivalente a:
$$a-\epsilon<a_n<a+\epsilon$$
ma allora per ogni $\epsilon < a$ si ha $a_n>0$.
\end{proof}

\begin{theorem}[Del confronto o \emph{dei due carabinieri}]
se $a_n\leq b_n \leq c_n$ definitamente e: 
$$a_n\to l, c_n \to l \in \R$$
allora anche $b_n\to l$.
\end{theorem}
\begin{proof}
Per definizione di limite, si ha che, comunque fissato $\epsilon >0$, definitivamente sia $\{a_n\}$ che $\{c_n\}$ giacciono in un $\epsilon$-intorno di $l$. Da $a_n\leq b_n\leq c_n$ segue che anche $\{b_n\}$ deve  definitivamente appartenere ad un $\epsilon$-intorno di $l$, e vista l'arbitrarietà di $\epsilon$ si ha $\lim_{n\to +\infty} b_n = l$. 
\end{proof}

\begin{definizione} Una \emph{sottosuccessione} di $\{a_n\}$ è una qualunque successione della forma $\{a_{n_k}\}_{k\geq 1}$\\ con $n_1 < n_2 < n_3 < \ldots$. 
\end{definizione}

\begin{theorem}[Bolzano-Weierstrass]
Ogni successione di numeri reali contenuta in un intervallo limitato $[a,b]$ possiede una sottosuccessione convergente in $[a,b]$.\end{theorem}
\begin{proof}
Sia $\{x_n\}$ la nostra successione, Dividiamo l'intervallo $[a,b]$ in due sotto intervalli di uguale ampiezza. Almeno uno di questi intervalli conterrà infiniti elementi di $\{x_n\}$, scegliamone uno, $x_0$. Chiamiamo questo intervallo $[a_1,b_1]$, peschiamo un elemento da $[a_1,b_1]$, $x_1$ e procediamo così ottenendo una successione di intervalli $[a_k,b_k]$ e una sottosuccessione $x_{n_k}$ con le seguenti proprietà:
\begin{itemize}
\item $\{a_k\}$ è monotona crescente e superiormente limitata da $b$
\item $\{b_k\}$ è monotona decrescente e inferiormente limitata da $a$
\item $b_k-a_k=\frac{b-a}{2^k}$
\item $x_{n_k}\in [a_k,b_k]$
\end{itemize}
le prime due convergono per il teorema di monotonia e tendono allo stesso limite, $c$.\\ Per confronto anche $x_{n_k}\to c\in [a,b]$.
\end{proof}

\begin{definizione}[Successione di Cauchy]
Si dice che la successione $\{a_n\}$ è \emph{di Cauchy} se
$$\forall\epsilon>0 \;\exists\, n_0:\forall n,m\geq n_0, |a_n-a_m|<\epsilon.$$
\end{definizione}
Vista la somiglianza con la definizione di successione convergente, è semplice verificare che\\
$(i)$ se una successione è convergente allora è di Cauchy \\
$(ii)$ se una successione è di Cauchy allora è limitata.\\
Vale inoltre il seguente
\begin{theorem}[Completezza dei reali]
Se $\{a_n\}$ è una successione di Cauchy di reali, $a_n\to l\in\mathbb{R}$.\end{theorem}
\begin{proof}
Poiché $\{a_n\}$ è di Cauchy questa è limitata. Per Bolzano-Weierstrass ammette allora una sottosuccessione $\{a_{n_k}\}$ convergente ad un certo limite $l$. 
Mostriamo che l'intera successione converge ad $l$. Infatti:
$$|a_n-l|\leq|a_n-a_{n_k}| +|a_{n_k}-l|$$ e fissato $\epsilon>0, |a_{n_k}-l|<\epsilon$ definitivamente e quindi in particolare vale $|a_n-a_{n_k}|<\epsilon$ definitivamente, perciò: $$|a_n-l|<2\epsilon$$
definitivamente.
\end{proof}

\textbf{Nota}: l'enunciato in $\Q$ è falso. Basta considerare la successione a valori in $\Q$ data da $\left\{\frac{F_{n+1}}{F_n}\right\}_{n\geq 0}$, dove il termine generale è il rapporto tra due numeri di Fibonacci consecutivi. Questa è una successione di Cauchy sia in $\Q$ che in $\R$, ma il suo limite (ossia il rapporto aureo) non appartiene a $\Q$.

\subsection{Continuità}
\begin{definizione}[Continuità]
Se $f:I\to\R$, $I$ un intervallo, e $c\in I$ si dice che $f$ è \emph{continua in $c$} se esiste $\lim_{x\to c}f(x)$ e questo coincide con $f(c)$. 
$f$ si dice \emph{continua} in $I$ se è continua in ogni punto di $I$. \end{definizione}

\begin{theorem}[Degli zeri] Sia $f$ continua in $[a,b]$ e $f(a)\cdot f(b)<0$ allora esiste $c\in (a,b)$ tale che $f(c)=0$.\\ Se $f$ è strettamente monotona lo zero è unico per iniettività di $f$.
\end{theorem}
\begin{proof}
Costruiamo una successione che tende ad uno zero di $f$. Posto $c_1=\frac{a+b}{2}$ se $f(c_1)=0$ abbiamo vinto, altrimenti guardiamo il segno di $f(a)\cdot f(c_1)$. Ora se $f(a)\cdot f(c_1)<0$ consideriamo $[a_1,b_1]$ con $a_1=a$ e $b_1=c_1$, altrimenti $a=c_1$ e $b_1=b$. ponendo adesso $c_2=\frac{a_1+b_1}{2}$ possiamo ripetere la procedura di sopra fino a che non troviamo lo zero cercato. Infatti le successioni $\{a_n\}$ e $\{b_n\}$ sono limitate e monotone, hanno quindi limiti finiti, che chiamiamo rispettivamente $l_1$ ed $l_2$. 
Osservando che $a_n - b_n\to 0$ abbiamo che $l_1=l_2=l$, dunque $f(l)=0$.
\end{proof}


\begin{theorem}[Weierstrass]
Se $f:[a,b]\to \R$ una funzione continua, allora $f$ assume massimo e minimo in $[a,b]$.\end{theorem}
\begin{proof} È sufficiente provare che per qualche $c\in[a,b]$ si ha $f(c)=\sup_{x\in[a,b]}f(x)$, per poi applicare il medesimo lemma a $-f(x)$. Proviamo preliminarmente che $f$ è necessariamente superiormente limitata. Se così non fosse, esisterebbe una qualche successione $\{x_n\}_{n\geq 1}$ di elementi di $[a,b]$ tale per cui $f(x_n)\geq n$ per ogni $n\in\N^+$.\\ Per Bolzano-Weierstrass esisterebbe una estratta $\{x_{n_k}\}_{k\geq 1}$ convergente a $\overline{x}\in[a,b]$, e dalla continuità di $f$ si avrebbe 
$$f(\overline{x})=\lim_{k\to +\infty} f(x_{n_k}) = +\infty, $$
contro l'ipotesi che $f$ abbia valori reali in tutti i punti di $[a,b]$. Provato che l'immagine di $[a,b]$ secondo $f$ è superiormente limitata, poniamo $\Gamma=\sup_{x\in[a,b]}f(x)$. Per definizione di $\sup$, per ogni $n\in\N^+$ esiste un $x_n\in[a,b]$ tale per cui $f(x_n)\geq \Gamma-\frac{1}{n}$. Analogamente a prima, dalla successione $\{x_n\}_{n\geq 1}$ è possibile estrarre una sottosuccessione $\{x_{n_k}\}_{k\geq 1}$ convergente a $\overline{x}\in[a,b]$, e dalla continuità di $f$ segue 
$$ f(\overline{x})= \lim_{k\to +\infty} f(x_{n_k}) = \Gamma. $$
 
\end{proof}


\begin{theorem}[Dei valori intermedi]
Se $f:[a,b]\to \R$ è una funzione continua, allora $f$ sul suo dominio assume tutti i valori compresi tra $f(a)$ e $f(b)$.
\end{theorem}
\begin{proof}
Se $f(a)=f(b)$ non c'è alcunché da dimostrare. Possiamo allora assumere $f(a)\neq f(b)$ e per qualunque $c$ compreso tra $f(a)$ ed $f(b)$ applicare il teorema degli zeri a $f(x)-c$. 
\end{proof}


\begin{theorem}[Invertibilità]
Una funzione continua $f$ da un intervallo chiuso $I$ in $\R$ è invertibile se e solo se è strettamente monotona, e in tal caso ha inversa continua e strettamente monotona. 
\end{theorem}
\begin{proof}

Se $f:I\to \R$ continua e invertibile non fosse strettamente monotona, esisterebbero tre punti ${x_1<x_2<x_3}$ in $I$ tali che $f(x_2)\leq \min(f(x_1),f(x_3))$ oppure $f(x_2)\geq \max(f(x_1),f(x_3))$. In entrambi i casi, dal Teorema dei valori intermedi seguirebbe $f(\alpha)=f(\beta)$ con $\alpha\in[x_1,x_2]$, $\beta\in[x_2,x_3]$ e $\alpha\neq\beta$, contro l'iniettività di $f$.\\
Per quanto concerne la seconda parte, consideriamo una generica $f:I\to\mathbb{R}$ continua e strettamente monotona. Per Bolzano-Weierstrass questa manda i punti dell'intervallo $I$ nei punti di un intervallo $J$, e a meno di ``rovesciare'' gli elementi del dominio possiamo supporre che $f$ mandi con continuità $I$ in $J$ preservando l'ordine stretto. Questo ci dà immediatamente la stretta monotonia della funzione inversa $g:J\to I$, e resta da provare unicamente la continuità di $g$. Supponiamo che $\{y_n\}_{n\geq 1}$ sia una successione di elementi di $J$ convergente a $\overline{y}\in J$, e poniamo $x_n=g(y_n)$, equivalente a $y_n=f(x_n)$. Per Bolzano-Weierstrass $\{x_n\}_{n\geq 1}$ ammette una estratta $\{x_{n_k}\}_{k\geq 1}$ che è sia strettamente monotona che convergente a $\overline{x}\in I$. Per continuità di $f$ la successione $\{y_{n_k}\}_{k\geq 1}$ converge a $f(\overline{x})$. Poiché $\{y_n\}_{n\geq 1}$ è convergente per ipotesi, qualunque sua estratta deve ammettere lo stesso limite, $\overline{y}=f(\overline{x})$. Segue che l'intera successione $\{x_n\}_{n\geq 1}$ converge a $\overline{x}$ e che $g$ manda successioni convergenti in successioni convergenti, ossia è (sequenzialmente) continua. Se infatti $\{x_n\}_{n\geq 1}$ ammettesse estratte convergenti a punti diversi, per continuità e stretta monotonia di $f$ lo stesso varrebbe per $\{y_n\}_{n\geq 1}$, contro le ipotesi.
\end{proof}


\begin{definizione}[Continuità Uniforme]
Si dice che $f:I\to\R$ è uniformemente continua in $I$ se 


$$\forall\epsilon>0\; \exists\,\delta>0: \forall x_1,x_2\in I\text{ vale che } |x_1-x_2|<\delta \Rightarrow |f(x_1)-f(x_2)|<\epsilon.$$
\end{definizione}

\begin{theorem}[Heine-Cantor]
Se $f:[a,b]\to\R$ è continua, allora è uniformemente continua in $[a,b]$.
\end{theorem}
\begin{proof}
Comunque fissato $\epsilon > 0$, per ogni $x\in[a,b]$ esiste un $\delta_x > 0$ che assicura $$|z-x|<\delta_x\Longrightarrow|f(z)-f(x)|<\epsilon.$$
Gli intervalli della forma $(x-\delta_x, x+\delta_x)$ costituiscono un ricoprimento aperto di $[a,b]$. Per compattezza di $[a,b]$ esiste un sotto-ricoprimento finito costituito da $(x_1-\delta_{x_1},x_1+\delta_{x_1}),\ldots,(x_n-\delta_{x_n},x_n+\delta_{x_n})$. Posto $\delta=\max(\delta_{x_1},\ldots,\delta_{x_n})$ si ha di conseguenza che sul dominio di $f$
$$|z-x|<\delta\Longrightarrow|f(z)-f(x)|<\epsilon.$$
\end{proof}


\begin{definizione}[Modulo di Continuità]
Sia $f:(a,b)\to\R$ una funzione a valori in $\R$, e sia $\delta$ un numero reale positivo. Si definisce Modulo di Continuità locale di $f$ in $x_0$ una funzione $\omega_0:\R^+\to\R^+$  tale che:\\
$$|f(x_0)-f(x)|\leq\omega_{x_0}(\delta),\forall x\in(a,b):|x_0-x|\leq\delta$$ è detto modulo di continuità globale invece:
$$|f(x_0)-f(x)|\leq\omega_{x_0}(\delta),\forall x,x_0\in(a,b):|x_0-x|\leq\delta$$
\end{definizione}



Il modulo di Continuità misura l'uniforme continuità di $f$, in particolare valgono le seguenti proprietà:
\begin{itemize}
 \item $f$ è continua in $x_0$ se e solo se essa ammette un modulo di continuità locale $\omega_{x_0}$ tale che $\lim_{\delta\to0}\omega_{x_0}(\delta)=0$
 \item una funzione è uniformemente continua se e solo se ammette un modulo di continuità globale $\omega_f$ tale che $\lim_{\delta\to 0}\omega_f(\delta)=0$
 \item per funzioni derivabili su un intervallo e lipschitziane di costante $L$ il modulo di continuità ha crescita sub-lineare, cioè $\omega_f(\delta)\leq C\delta$.
\end{itemize}


\begin{theorem}[Integrabilità delle funzioni continue]
Se $f:[a,b]\to\R$ è continua, allora è Riemann-integrabile su $[a,b]$.
\end{theorem}
\begin{proof}
Data una partizione di $[a,b]$ di calibro $\epsilon$, l'uniforme continuità di $f$ assicura che su ogni componente della partizione si abbia $\sup f-\inf f \leq \epsilon$. In particolare la differenza tra l'$\inf$ delle somme di Riemann superiori e il $\sup$ delle somme di Riemann superiori è controllato da $\epsilon(b-a)$. Dall'arbitrarietà di $\epsilon$ segue la Riemann-integrabilità di $f$. 
\end{proof}

Per quanto la dimostrazione richieda elementi di Teoria della Misura, è importante sapere che vale anche una sorta di viceversa:

\begin{theorem}[Riemann-Lebesgue] Se $f:[a,b]\to\mathbb{R}$ è Riemann-integrabile, l'insieme dei punti di discontinuità di $f$ ha misura di Lebesgue nulla. 
\end{theorem}



\subsection{Spazi metrici e di Banach}
Sia $X$ un insieme e sia $d:X \times X\to [0,+\infty]$ una funzione che ad ogni coppia $(x,y)$ di punti in $X$ associa un numero reale $d(x,y)\geq0$. Si dice che $d$ è una distanza o metrica su $X$ se sono verificate le seguenti:
\begin{itemize}
\item  $d(x,y)=0 \Leftrightarrow x=y\quad\forall x,y\in X$
\item $d(x,y)=d(y,x)\quad\forall x,y\in X$
\item $d(x,y)\leq d(x,z)+d(z,y)\quad\forall x,y,z\in X$
\end{itemize}
L'ultima condizione prende il nome di \textbf{Disuguaglianza Triangolare}.\\
La coppia $(X,d)$ si dice \textbf{Spazio Metrico} se $d$ è una distanza (o metrica).

\begin{definizione}[Intorno circolare]
Per ogni $x_0\in X$ e per ogni $r>0$, si chiama Intorno Circolare (Intorno Sferico o Palla Aperta) di centro $x_0$ e di raggio $r$ l'insieme $$B_r(x_0)=\{x\in X: d(x,x_0)<r\}.$$
\end{definizione}

\begin{definizione}[Aperti e Topologia]
Un insieme $A\subseteq X$ Si dice aperto se ogni suo punto è centro di una palla aperta contenuta in $A$, cioè se per ogni suo punto $x_0\in A$ esiste $r>0$ tale che $B_r(x_0)\subseteq A$ (si assume il vuoto come un insieme aperto). Un insieme $C\subseteq X$ si dice chiuso se il suo complementare, $A=X\setminus C$ è aperto. L'insieme di tutti gli aperti di uno spazio metrico $(X,d)$ si dice \textbf{Topologia Generata dalla metrica $d$}.
\end{definizione}

\textbf{Proposizione}. In uno spazio metrico, tutti le palle aperte, le unioni arbitrarie di aperti e le intersezioni finite di aperti sono aperte.\\
\textbf{Proposizione}. In uno spazio metrico intersezioni arbitrarie e unioni finite di chiusi danno luogo a insiemi chiusi.\\

Uno stesso insieme può avere metriche diverse a seconda della funzione $d$. Ad esempio: \\
Sia $(X,d)$ una metrica dove $X$ è un insieme e

$$ d(x,y)=\left\{\begin{array}{ccl} 0 &\text{se} & x=y\\ 1 &\text{se} & x\neq y\end{array}\right. $$

è chiaro che $d$ è una metrica, che prende il nome di metrica discreta. Segue anche che, secondo questa metrica, ogni sottoinsieme di $X$ è aperto.\\
Invece $d(x,y)=|x-y|$ definisce una metrica che prende il nome di euclidea, la quale genera l'usuale topologia della retta reale. In questo caso un insieme è aperto se e solo se è intorno di ogni suo punto.\\
Si può definire la convergenza di successioni e di funzioni continue attraverso una metrica. Infatti sia $a_n$ una successione in $X$, si dice che la successione converge, o tende, a $x_0\in X$ se per ogni $\epsilon>0$ esiste $v\in \N$ tale che, per ogni $k>v$: \\
$$d(a_k,x_0)<\epsilon.$$

Si prova in maniera analoga a come si fa in $\R$ che vale il \textbf{Teorema di unicità del limite}.

\subsection{*AN2* Successioni e Serie di Funzioni}
\textbf{Definizione}\\
Sia $I$ un insieme di numeri reali e sia $f_k:I\to\R$ una successione di funzioni reali. Si dice che $f_k$ converge puntualmente in $I$ verso la funzione $f:I\to\R$ se vale $$\lim_{k\to\infty} f_k(x)=f(x)$$
per ogni $x\in I$, cioè se per ogni $\epsilon>0$ e per ogni $x\in I$ esiste $v_{\epsilon,x}\in\N$ tale che:
$$|f_k(x)-f(x)|<\epsilon$$ In generale, fissato $\epsilon$, il numero  $v_{\epsilon,x}$ dipende solo da $x$, se risulta indipendente invece, si dice che la successione di funzioni converge uniformemente a $f(x)$.\\
La convergenza Uniforme implica quella Puntuale come mostrato nella disuguaglianza: $$|f_k(x) -f(x)|\leq \sup\{|f_k(x)-f(x): x\in I|\}$$
Per ogni $x\in I$. In generale il viceversa è falso.
\begin{theorem}
Sia $(X,d)$ uno spazio metrico e sia $x_0$ un fissato punto di $X$. Allora la funzione: $$x\in X\to d(x,x_0)$$
è continua da $X$ verso $\R$ (dotato della metrica euclidea)
\end{theorem}
\begin{proof}
    Applicando la disuguaglianza di Lipschitzianità della distanza si ha che per $x,y\in A$:
    $$|d(y,x_0)-d(x,x_0)|\leq d(x,y)$$
    Allora se $x_0$ è una successione di punti convergenti ad $x$, si ha: 
    $$|d(x_k,x_0)-d(x,x_0)|\leq d(x_k,x)$$
    e perciò $d(x_k,x_0)\to d(x,x_0)\text{ per } k\to\infty$.
\end{proof}
\begin{definizione}[Spazio Normato]
Sia $V$ uno spazio vettoriale. Una norma su $V$ è una funzione che ad ogni vettore $x\in V$ associa un reale $\|x\|\geq 0$ che verifica le seguenti condizioni:
\begin{itemize}
    \item $\|x\|=0 \text{ se e solo se } x=0 \qquad \forall x\in V$
    \item $\|\lambda x\|=|\lambda|\cdot\|x\|\qquad \forall\lambda\in\R,\; \forall x\in V$
    \item $\|x+y\|\leq \|x\|+\|y\|\qquad \forall x,y\in V$
\end{itemize}
\end{definizione}
L'ultima disequazione prende il nome di \emph{disuguaglianza triangolare}.
\begin{definizione}[Spazio di Banach]
Sia $(X,d)$ uno spazio normato, se esso risulta completo completo come spazio metrico rispetto alla distanza: $$d(x,y)=\|x-y\|_V$$ generata dalla norma $\|\cdot\|_V$, diremo che $V$ è uno spazio di Banach.    
\end{definizione}
\subsection{Funzioni Lipschitziane e teorema delle contrazioni}
\begin{definizione}[Funzione L-Lip]
Siano $(X,d_X)$ e $(Y,d_Y)$ due spazi metrici e sia $f:X\to Y$ una funzione.\\ Diremo che $f$ è lipschitziana se esiste una costante $L$ tale che: $$d_Y(f(x),f(y))\leq L\cdot d_X(x,y)\qquad \forall x,y\in X$$    
\end{definizione}
Se $f:X\to Y$ è L-Lip chiaramente è anche continua in $X$.
\begin{definizione}[Contrazione]
Una $f:X\to X$ Lipschitziana con costante $L<1$, cioè tale per cui
$$\exists L\in[0,1): d(f(x),f(y))\leq L\cdot d(x,y)\qquad\forall x,y\in X$$
prende il nome di \emph{contrazione} sullo spazio $(X,d)$.
\end{definizione}
\begin{theorem}[Teorema delle Contrazioni (Banach)]
Sia $(X,d)$ uno spazio metrico completo e sia $f:X\to X$\\ una contrazione. Allora esiste uno ed un solo punto $x\in X$ tale che $f(x)=x$. $x$ si chiama \emph{punto fisso}.    
\end{theorem}
\begin{proof} A partire da un qualunque $x_0\in X$ possiamo definire una successione a valori in $X$\\ attraverso $x_{n+1}=f(x_n)$. Si ha che 
$$d(x_{n+2},x_{n+1}) = d(f(x_{n+1}),f(x_n)) \leq L\cdot d(x_{n+1},x_n), $$
$$d(x_{n+3},x_{n+2}) \leq L\cdot d(x_{n+2},x_{n+1}) \leq L^2\cdot d(x_{n+1},x_n)$$
e per induzione $d(x_{n+k+1},x_{n+k})\leq L^k\cdot d(x_{n+1},x_{n})$. Dalla disuguaglianza triangolare segue pertanto 
$$ d(x_{n+k+1},x_{n}) \leq \left(1+L+L^2+\ldots+L^k\right)\cdot d(x_{n+1},x_n)\leq \frac{d(x_{n+1},x_n)}{1-L}\leq \frac{L^n}{1-L}\cdot  d(x_1,x_0).$$
L'ultima disuguaglianza comporta che $\{x_n\}_{n\geq 0}$ sia una successione di Cauchy e la completezza di $X$ comporta che $x_n\to \overline{x} \in X$. Dalla continuità di $f$ segue inoltre $x_{n+1}=f(x_n)\to f(\overline{x})$, dunque $\overline{x}$ è necessariamente un punto fisso di $f$. Abbiamo infine che $\overline{x}$ non dipende da $x_0$: se $f$ avesse due distinti punti fissi $\overline{x}_1$ e $\overline{x}_2$ avremmo 
$$ d(\overline{x}_1,\overline{x}_2) = d(f(\overline{x}_1),f(\overline{x}_2)) \leq L\cdot d(\overline{x}_1,\overline{x}_2) < d(\overline{x}_1,\overline{x}_2) $$
che è una contraddizione. Segue che per qualunque $x_0\in X$ la successione data da $x_{n+1}=f(x_n)$ converge verso l'unico punto fisso di $f$.   
\end{proof}

La stessi tesi vale in ipotesi leggermente meno forti.

\begin{definizione}[Funzione contrattiva o contrazione debole] Se $(X,d)$ è uno spazio metrico e $f:X\to X$ è tale per cui  $d(f(x),f(y))<d(x,y)$ per ogni $x,y$ distinti in $X$, $f$ è detta \emph{funzione contrattiva} o \emph{contrazione debole}. 
\end{definizione}

\begin{theorem}[Teorema delle contrazioni deboli (Banach-Caccioppoli)] Se $(X,d)$ è uno spazio metrico compatto rispetto alla topologia indotta da $d$) e $f:X\to X$ è una contrazione debole, per ogni $x_0\in X$ la successione definita da $x_{n+1}=f(x_n)$ converge all'unico punto fisso di $f$. 
\end{theorem}

\begin{proof}
In quanto funzione $1$-Lip, $f$ è uniformemente continua e lo stesso vale per $g(x)=d(f(x),x)$.\\ Per il Teorema di Weierstrass una funzione continua su un compatto ammette minimo, e il minimo di $g(x)$ su $X$ deve essere necessariamente zero. Se infatti il valore minimo di $g$ fosse $m>0$, assunto in $\overline{x}$, per contrattività di $f$ si avrebbe 
$$ g(f(\overline{x})) = d(f(f(\overline{x})),f(\overline{x})) < d(f(\overline{x}),\overline{x}) = m $$
contro la minimalità di $m$. Questo prova che $f$ ha necessariamente un punto fisso in $X$, e per discorsi analoghi a quelli appena fatti, il punto fisso deve essere unico. Per Bolzano-Weierstrass qualunque successione $\{x_n\}_{n\geq 0}$ ammette una sottosuccessione $\{x_{n_k}\}_{k\geq 0}$ convergente, e per continuità di $f$ tale sottosuccessione è necessariamente convergente a $\overline{x}$. La contrattività di $f$ comporta ora che l'intera successione $\{x_n\}_{n\geq 0}$ sia convergente a $\overline{x}$. Per ogni $\epsilon > 0$,  dalla convergenza di $\{x_{n_k}\}_{k\geq 0}$ abbiamo che definitivamente, diciamo per $k\geq K$, $x_{n_k}$ è in un intorno di raggio $\epsilon$ di $\overline{x}$.\\ 
Per contrattività di $f$ la successione $\{g(x_n)\}_{n\geq 0}$ è strettamente decrescente, dunque converge al suo $\inf$.\\ Poiché $g(x_{n_k})\to g(\overline{x}) = 0$, il precedente $\inf$ è nullo e $d(x_n,f(x_n))$ converge a zero.\\ Per unicità del punto fisso di $f$, $x_n\to\overline{x}$.\end{proof}

\subsection{Compattezza}
\begin{definizione}[Insieme Compatto]
    Un sottoinsime $K$ dello spazio metrico $(X,d)$ si dice (sequenzialmente) compatto se da ogni successione $\{x_k\}$ di punti di $K$ si può estrarre una sottosuccessione convergente verso un punto $x\in K$.
\end{definizione}
Osservimo che, se $K\subseteq X$ è un insieme compatto, si dice, secondo questa definizione, che è \emph{compatto per successioni}, a dispetto della definizione di compattezza data attraverso dei \emph{ricoprimenti aperti}. In ogni caso, le due definizioni risultano equivalenti.
\begin{theorem}
    Se $(X,d)$ è uno spazio metrico e $K\subseteq X$ è un insime compatto, allora $K$ è chiuso.
\end{theorem}
\begin{proof}
    sia $x_k$ una successione di punti di $K$ convergente verso il punto $x\in X$. Dimostriamo che $x\in K$. Essendo $K$ compatto estraiamo da $x_k$ una sottosuccessione $x_{k_h}$, questa è convergente verso il punto $x_0\in K$. Necessariamente $x=x_0$ e si ha che $x\in K$
\end{proof}
\begin{theorem}[Heine-Borel]
Un sottoinsieme $K$ di $\R^n$ è compatto se e solo se è chiuso e limitato.    
\end{theorem}
\begin{proof}
 Se $K$ è chiuso e limitato, sia $\{x_k\}_{k\geq 1}=\{\left(x_{k_1},x_{k_2},\dots,x_{k_n}\right)\}_{k\geq 1}$ una successione di punti di $K$.\\ Le successioni $\{x_{k_i}\}_{k\geq 1}$ sono successioni limitate di reali. Per il teorema di Bolzano-Weierstrass dalla successione $\{x_k\}_{k\geq 1}$ se ne può estrarre una avente la prima coordinata convergente; da questa un'altra con seconda coordinata convergente, e così via fino ad $n$. Si ottiene così una successione strettamente crescente $\{k_h\}_{h\geq 1}$ di numeri naturali tale che  $x_{k_h,i}\to x_i$ per ogni $i=1,2,3,\dots,n$. Pertanto $x_k\to x=(x_1,x_2,\dots,x_n)$.\\
 Essendo $K$ chiuso ne segue che $x\in K$ e quindi $K$ è compatto.\\ Viceversa se $K$ è compatto esso è chiuso per la proposizione precedente. Se $K$ non fosse limitato, esisterebbe una successione $\{x_k\}_{k\geq 1}$ di punti di $K$ tale che: $$\lim_{k\to\infty}|x_k|=+\infty$$ e da questa non si potrebbe estrarre alcuna successione convergente, contro l'ipotesi che $K$ sia compatto.
\end{proof}
\subsection{Calcolo differenziale}
Saranno elencati i principali risultati sulle funzioni continue e derivabili in intervalli, dei must have in ogni corso di analisi 1.
\begin{theorem}[Rolle]
Sia $f:[a,b]\to\R$ una funzione continua e derivabile in $(a,b)$ e tale che $f(a)=f(b)$. Allora esiste un punto $c\in[a,b]$ tale che $f'(c)=0$.   
\end{theorem}
\begin{proof}
    Per il teorema di Weierstrass f ammette massimo e minimo in $[a,b]$, rispettivamente $x_M$ e $x_m$. Abbiamo quindi 2 casi:
    il minimo e il massimo sono prorprio gli estremi dell'intervallo $[a,b]$, allora il massimo di $f$ coincide col suo minimo, quindi la funzione vale costantemente $f(x_M)=f(x_m)=k$, cioè ha derivata costantemente nulla. \\
    Alternativamente uno tra $x_m$ e $x_M$ cade in $(a,b)$, quindi la derivata si annulla in almeno in quel punto.
\end{proof}
\begin{theorem}[Lagrange o Valor Medio]
Sia $f:[a,b]\to\R$ e derivabile in $(a,b)$. Esiste u punto $\xi\in(a,b)$ tale che: $$f(b)-f(a)=f'(\xi)(b-a)$$
\end{theorem}
\begin{proof}
    La funzione $$g(x)=f(x)-f(a)-\frac{f(b)-f(a)}{b-a}(x-a)$$ è continua in $[a,b]$ e derivabile in $(a,b)$ e. Inoltre si ha $g(a)=g(b)=0$ quindi per il teorema di Rolle, esiste un punto $\xi\in(a,b)$ take che $g'(\xi)=0$ da cui: $$f'(\xi)\frac{f(b)-f(a)}{b-a}$$
\end{proof}
\begin{oss}
    Il teorema di Lagrange ha un interessante interpretazion geometrica; la retta che unisce i punti $(a,f(a))$ e $(b,f(b))$ ha equazione $y=f(a)+\frac{f(b)-f(a)}{b-a}(x-a)$, dunque di coefficiente angolare $\frac{f(b)-f(a)}{b-a}$, mentre $f'(\xi)$ è il coefficiente angoalare della retta tangente ad $f$ nel punto $\xi$. Il teorema di Lagrange assicura che esiste un punto che dove la tangente alla funzione in quel punto ha lo stesso coefficiente angolare della retta che unisce gli estremi dell'intervallo.
\end{oss}
\begin{theorem}[Cauchy]
    Siano $f(x)$ e $g(x)$ continue in $[a,b]$ e derivabili in $(a,b)$. Esiste un punto $\xi\in(a,b)$ in cui:
    $$[g(b)-g(a)]f'(\xi)=[f(b)-f(a)]g'(\xi)$$
\end{theorem}
\begin{proof}
    La funzione: $$h(x)=[g(b)-g(a)]f(x)-[f(b)-f(a)]g(x)$$ verifica tutte le ipotesi del teorema di Rolle, allora esiste un punto $\xi\in(a,b)$ in cui questa si annulla. 
\end{proof}
\begin{theorem}[De l'Hopital 1]
    Siano $f(x)$ e $g(x)$ continue in $[a,b]$ e derivabili in $(a,b)$, con la possibile eccezione di un punto $x_0$. Supponiamo $f(x_0)=g(x_0)=0$ e che $g(x)$ e $g'(x)$ non si annullino mai $x\neq x_0$. Supponiamo anche che il limite del rapporto delle derivate: $$\lim_{x\to x_0}\frac{f'(x)}{g'(x)}=L$$ Allora esiste anche il rapporto delle funzioni ed è uguale al precedente $$\lim_{x\to x_0}\frac{f(x)}{g(x)}=L$$ 
\end{theorem}
\begin{proof}
    Sia $x\in(a,b)$, per Cauchy, esiste un punto $\xi(x)\in(x_0,x)$ (anche se dipende da $x$ lo chiameremo semplicemente $\xi$ per non appesantire la notazione) tale che $$\frac{f(x)}{g(x)}=\frac{f(x)-f(x_0)}{g(x)-g(x_0)}=\frac{f'(\xi)}{g'(\xi)}$$ quando $x\to x_0$ anche $\xi\to x_0$ si ha dunque $$\lim_{x\to x_0}\frac{f(x)}{g(x)}=\lim_{x\to x_0}\frac{f'(\xi)}{g'(\xi)}$$
\end{proof}
\begin{theorem}[De l'Hopital 2]
    Siano $f(x)$ e $g(x)$ due funzioni derivabili in $[a,b]-{x_0}$. Supponiamo che per $x\to x_0$ entrambe tendano a $+\infty$ e che $g'(x)$ non si annulli mai in un intorno di $x_0$. Supponiamo infine che esiste il rapporto delle derivate $$\lim_{x\to x_0}\frac{f'(x)}{g'(x)}=L$$
    Allora esiste anche il rapporto delle funzioni ed è uguale al precedente $$\lim_{x\to x_0}\frac{f(x)}{g(x)}=L$$
\end{theorem}
\begin{proof}
    Iniziamo dimostrando il caso in cui $x_0$ sia uno degli estremi, ad esempio $a$. Il caso generale segue considrando separatamente il limite destro e sinistro. Dato che $x\to a$ possiamo restringerci ad un intorno in cui sia $g'(x)$ che $g(x)$ siano diversi da 0 (per la permanenza del segno).
    Supponiamo che $L$ sia finito. $\forall \epsilon,0<\epsilon<1$, esiste un $x_1>a$ tale che $\forall\xi\in(a,b)$ risulta $$L-\epsilon<\frac{f'(\xi)}{g'(\xi)}<L+\epsilon$$ se $x\in(a,x_1)$, per il teorema di Cauchy esiste $\xi\in(x,x_1)$ tale che $$\frac{f(x)-f(x_1)}{g(x)-g(x_1)}=\frac{f'(\xi)}{g'(\xi)}$$
    e quindi $\forall x\in(a,x_1)$ $$L-\epsilon<\frac{f(x)-f(x_1)}{g(x)-g(x_1)}< L+\epsilon$$ D'altronde $$\frac{f(x)-f(x_1)}{g(x)-g(x_1)}=\frac{f(x)}{g(x)}\ \frac{1-\frac{f(x_1)}{f(x)}}{1-\frac{g(x_1)}{g(x)}}.$$ 
    e quindi $$\frac{f(x)}{g(x)}=\frac{f(x)-f(x_1)}{g(x)-g(x_1)}\ \frac{1-\frac{g(x_1)}{g(x)}}{1-\frac{f(x_1)}{f(x)}}$$
    Dato che $x\to a$ sia $f(x)$ che $g(x)$ tendono a $+\infty$ , la quantità: $$Q(x)=\frac{1-\frac{g(x_1)}{g(x)}}{1-\frac{f(x_1)}{f(x)}}$$
    tende ad 1. Esisterà dunque un punto $x_2\leq x_1$ tale che $\forall x\in(a,x_2)$ risulta $1-\epsilon<Q(x)<1+\epsilon$ Di conseguenza (per la stima precedentemente fatta su $L\pm\epsilon$)
    $$(1-\epsilon)(L-\epsilon)z\frac{f(x)}{g(x)}<L+(L+\epsilon)(1+\epsilon)$$
    Per ogni $x\in(a,x_2)$ abbiamo $$(L+\epsilon)(1+\epsilon)=L+(L+1)\epsilon + \epsilon^2<L+(L+2)\epsilon$$
    e
    $$(L-\epsilon)(1-\epsilon)=L-(L+1)\epsilon + \epsilon^2<L-(L+2)\epsilon$$
    e quindi in conclusione
    $$L-(L+2)\epsilon<\frac{f(x)}{g(x)}<L+(L+2)\epsilon$$ e pertanto il rapporto $\frac{f(x)}{g(x)}$ tende ad $L$.
\end{proof}
\section{Binomiali \& Friends}
Come spero sia noto il binomiale $\binom{n}{k}$, letto \emph{$n$ su $k$}, rappresenta il numero di sottoinsiemi di cardinalità $k$ in un insieme di $n$ elementi.
Questo è esplicitamente:\\
$$\binom{n}{k} = \frac{n!}{(n-k)!k!}$$    

Proprietà dei binomiali sono: \\
\begin{itemize}
    \item $\binom{n}{k}=\binom{n}{n-k}$
    \item $\binom{n+1}{k+1}=\binom{n}{k+1} + \binom{n}{k}$
    \item $2^n= \sum_{k=0}^{n}\binom{n}{k}$
    \item $0 = \sum_{k=0}^{n}\binom{n}{k}(-1)^k$
\end{itemize}

\subsection{Teorema Binomiale di Newton e applicazioni utili}
Il binomio di Newton è usato per calcolare le potenze $n$-esime dei binomi:
$$(a+b)^n=\sum_{k=0}^{n}\binom{n}{k}a^{n-k}b^k$$
\\
\subsection{Stars \& Bars}
Un importante tecnica di conteggio è appunto \textbf{Stars \& Bars}:
$$\left|\{(x_1,\ldots,x_k)\in(\N^+)^k: x_1+\ldots+x_k = n\}\right|=[x^n]\left(\frac{x}{1-x}\right)^k = \binom{n-1}{k-1},$$
$$ \frac{1}{(1-x)^{k+1}}=\sum_{n\geq 0}\binom{n+k}{k}x^n. $$
L'interpretazione grafica è data dal rispondere alla domanda: in quanti modi possiamo mettere $k-1$ barrette nelle intercapedini tra $n$ oggetti adiacenti? Eccone anche un'applicazione ad un esercizio già visto, ossia la determinazione di $\sum_{n\geq 0}\frac{n^2}{4^n}$. Abbiamo in primo luogo che $n^2$ è certamente una combinazione lineare di $\binom{n+2}{2},\binom{n+1}{1}$ e $\binom{n}{0}=1$.\\ In particolare, per eliminazione gaussiana (o differenze in avanti) vale $n^2=2\binom{n+2}{2}-3\binom{n+1}{1}+\binom{n}{0}$.\\ Da stars\&bars segue allora che 

$$ \sum_{n\geq 0} n^2 x^n = \frac{2}{(1-x)^3}-\frac{3}{(1-x)^2}+\frac{1}{1-x} $$

e valutando ambo i membri in corrispondenza di $x=\frac{1}{4}$ si ha immediatamente 

$$ \sum_{n\geq 0}\frac{n^2}{4^n} = 2\left(\frac{4}{3}\right)^3-3\left(\frac{4}{3}\right)^2+\left(\frac{4}{3}\right)=\frac{20}{27}.$$
\subsection{Forma Binomiale}
Ogni potenza $n^k$ è combinazione lineare di coefficienti binomiali della forma $\binom{n}{j}$ con $j\leq k$. i coefficienti di queste combinazioni lineari sono ottenute per differenze in avanti ($\ast\ast$ da completare$\ast\ast$).
\\
\\
\subsection{Binomiale Centrale}
I coefficienti binomiali centrali sono i binomiali del tipo:
$$\binom{2n}{n}=\frac{(2n)!}{n!^2}=\frac{2^n(2n-1)!!}{n!}$$
così chiamati perché occupano le posizioni centrali del triangolo di Tartaglia.\\
Seguono disuguaglianze utili per la stima dei binomiali centrali:
    \begin{itemize}
        \item $\frac{4^n}{n+1}\leq\binom{2n}{n}\leq4^n$
        \item $\frac{4^n}{2\sqrt{n}}\leq\binom{2n}{n}\leq\frac{4^n}{\sqrt{3n+1}}$
    \end{itemize}
e ancora più accuratamente $\frac{1}{4^n}\binom{2n}{n}\sim\frac{1}{\sqrt{\pi n}}$ con $\frac{1}{4^n}\binom{2n}{n}\leq \frac{1}{\sqrt{\pi\left(n+\frac{1}{4}\right)}}$.\\ Queste possono essere ricavate dalla rappresentazione integrale 
$$ \frac{1}{4^n}\binom{2n}{n} = \frac{2}{\pi}\int_{0}^{\pi/2}\left(\cos\theta\right)^{2n}\,d\theta $$
    
\subsection{Hockey Stick Identity}
Vale l'identità:
$$\binom{n+1}{r+1}=\sum_{j=r}^{n}\binom{j}{r}$$
\begin{proof}
 Fissato $r$, è sufficiente procedere per induzione su $n$. In alternativa, è sufficiente catalogare i sottoinsiemi di taglia $r+1$ di $\{1,2,\ldots,n+1\}$ in base al loro elemento massimo.
\end{proof}


\section{Integrale di Riemann}
\begin{definizione}[Partizione] Dato un intervallo chiuso e limitato della retta reale $[a,b]$, una qualunque sequenza 
$$ a=a_0 < a_1 < \ldots < a_n = b $$
definisce una \textbf{partizione} di $[a,b]$:
$$ [a,b]=\bigcup_{k=1}^{n} I_k,\qquad I_k=[a_{k-1},a_{k}]. $$ 
\end{definizione}
\begin{definizione}[Calibro o finezza] Il \emph{calibro} o \emph{finezza} di una partizione è la massima lunghezza degli intervalli che costituiscono la partizione. 
\end{definizione}
\begin{definizione}[Ordinamento parziale delle partizioni] Date due partizioni $\mathcal{P}_1$ e $\mathcal{P}_2$ dello stesso intervallo, diciamo che $\mathcal{P}_1$ \emph{è più fine} di $\mathcal{P}_2$, in simboli $\mathcal{P}_1 \geq \mathcal{P}_2$, se gli estremi degli intervalli di $\mathcal{P}_1$ costituiscono una sottosequenza degli estremi degli intervalli di $\mathcal{P}_2$. Questo definisce una relazione d'ordine parziale sull'insieme delle partizioni: date due distinte partizioni $\mathcal{P}_1,\mathcal{P}_2$, non è detto che $\mathcal{P}_1$ sia più fine di $\mathcal{P}_2$ o viceversa. Tuttavia, date due distinte partizioni $\mathcal{P}_1,\mathcal{P}_2$, esiste sempre una partizione $\mathcal{P}_3$ più fine di entrambe: è sufficiente prendere gli estremi degli intervalli di $\mathcal{P}_3$ come quelle quantità che sono un estremo di un intervallo di $\mathcal{P}_1$ o (inclusivo) di $\mathcal{P}_2$.
\end{definizione}


L'\textbf{integrale di Riemann} in senso proprio si definisce a partire da $f:[a,b]\to\R$ limitate.

\begin{definizione}[Somme di Riemann superiori e inferiori]
Data una $f$ siffatta e una partizione $\mathcal{P}=\bigcup_{k=1}^{n}I_k$ di $[a,b]$, definiamo la \textbf{somma di Riemann superiore} $S^+_{\mathcal{P}}(f)$ e la  \textbf{somma di Riemann inferiore} $S^-_{\mathcal{P}}(f)$ nel seguente modo:

$$ S^+_{\mathcal{P}}(f) = \sum_{k=1}^{n} \mu(I_k) \sup_{x\in I_k} f(x), \qquad S^-_{\mathcal{P}}(f) = \sum_{k=1}^{n} \mu(I_k) \inf_{x\in I_k} f(x)$$
dove $\mu(I_k)$ denota la lunghezza di $I_k$, ossia $a_{k}-a_{k-1}$.
\end{definizione}

Seguono alcuni lemmi di immediata dimostrazione ma di cruciale importanza:
\begin{itemize}
 \item Per qualunque partizione $\mathcal{P}$ si ha $S^+_{\mathcal{P}}\geq S^-_{\mathcal{P}}$
 \item Se $\mathcal{P}_2$ è più fine di $\mathcal{P}_1$, $S^+_{\mathcal{P}_2} \leq S^+_{\mathcal{P}_1}$
 \item  Se $\mathcal{P}_2$ è più fine di $\mathcal{P}_1$, $S^-_{\mathcal{P}_2} \geq S^+_{\mathcal{P}_1}$
\end{itemize}

\begin{definizione}[Integrale di Riemann]
I precedenti lemmi comportano l'esistenza e la finitezza sia di $\sup_{\mathcal{P}}S^-_{\mathcal{P}}$, detto \emph{integrale di Riemann inferiore}, che di $\inf_{\mathcal{P}}S^+_{\mathcal{P}}$, detto \emph{integrale di Riemann superiore}. È automatico che l'integrale di Riemann inferiore sia $\leq$ dell'integrale di Riemann superiore, ma non è affatto automatico che tali quantità coincidano. Se coincidono, $f$ è detta \emph{Riemann-integrabile} su $[a,b]$ e il valore di $\sup_{\mathcal{P}}S^-_{\mathcal{P}}=\inf_{\mathcal{P}}S^+_{\mathcal{P}}$ è denotato come 
$$ \int_{a}^{b} f(x)\,dx. $$
\end{definizione}

\begin{theorem} Ogni $f\in C^0([a,b])$ è Riemann-integrabile su $[a,b]$ e realizza 
$$ \int_{a}^{b} f(x)\,dx = \lim_{N\to +\infty}\frac{b-a}{N}\sum_{k=1}^{N}f\left(a+\frac{k}{N}(b-a)\right) = \lim_{N\to +\infty}\frac{b-a}{N}\sum_{k=0}^{N-1}f\left(a+\frac{k}{N}(b-a)\right).$$
\end{theorem}
\begin{proof} Per Heine-Cantor $f$ è uniformemente continua su $[a,b]$, ossia per ogni $\epsilon > 0$ esiste un $\delta > 0$ che assicura 
$$ |x_1-x_2|\leq \delta\quad\Longrightarrow\quad |f(x_1)-f(x_2)|\leq \varepsilon.$$
Per qualunque partizione $\mathcal{P}$ di calibro $\leq \delta$ si ha pertanto che 
$$ S^+_{\mathcal{P}}- S^-_{\mathcal{P}} = \sum_{k=1}^{n}\mu(I_k)\left(\sup_{x\in I_k}f(x)-\inf_{x\in I_k}f(x)\right)= \sum_{k=1}^{n}\mu(I_k)\left(\max_{x\in I_k}f(x)-\min_{x\in I_k}f(x)\right)\leq \sum_{k=1}^{n}\mu(I_k)\epsilon = \epsilon (b-a). $$
Data l'arbitrarietà di $\epsilon$ si ha che l'integrale di Riemann inferiore e l'integrale di Riemann superiore hanno distanza arbitrariamente piccola, cioè nulla, visto che $\R$ è un campo archimedeo, dunque privo di infinitesimi. Ciò comporta la Riemann-integrabilità di $f$. L'uniforme continuità di $f$ comporta anche che l'integrale $\int_{a}^{b} f(x)\,dx$ coincida con il $\sup_{\mathcal{P}\in U} S^-_{\mathcal{P}}$ e con l'$\inf_{\mathcal{P}\in U} S^+_{\mathcal{P}}$ sull'insieme $U$ delle \emph{partizioni uniformi}, ossia quelle in cui tutti gli intervalli hanno lunghezza pari al calibro. All'interno dell'insieme di queste partizioni, nuovamente per uniforme continuità di $f$, sia 

$$ S^+_{\mathcal{P}}-\sum_{k=1}^{n}\mu(I_k) f(\max I_k)\quad\text{che}\quad S^-_{\mathcal{P}}-\sum_{k=1}^{n}\mu(I_k) f(\min I_k) $$
possono essere resi arbitrariamente vicini a zero in modulo. Questo prova le ultime due uguaglianze. 
\end{proof}





    \section{Criteri e Metodi per Serie Numeriche}
    \subsection{Serie Importanti}
Seguono le più importanti Serie Numeriche convergenti, utili nella stima di altre serie e nella verifica della loro convergenza.\\
\textbf{Serie Armonica Generalizzata}
$$\sum_{n=0}^{\infty}\frac{1}{n^\alpha}$$
è una serie convergente se e solo se
$\alpha\in\R>1$
\\
\textbf{Serie Geometrica}
$$S=\sum_{n=0}^{\infty}x^n$$
Ha il seguente comportamento:
\begin{equation*}
\begin{cases}
    |x|\in(0,1) \rightarrow S=\frac{1}{1-x}
    \\x \geq 1 \rightarrow S=\infty
    \\x\leq -1 \rightarrow \not\exists S
    
\end{cases}
\end{equation*}
\textbf{Serie Telescopica}
Ogni somma/serie in cui il termine generale si può esprimere come differenza di termini consecutivi (o quasi) si calcola, infatti vale
$$\sum_{n=0}^{N}\left(a_n - a_{n+1}\right) = a_0 - a_{N+1}$$
per massiccia cancellazione: il membro sinistro corrisponde alla differenza tra la prima quantità sommata e l'ultima quantità sottratta.
\subsection{Criteri}
Seguiranno i principali criteri di convergenza per le Serie.
\subsubsection{Serie a termini definitivamente non negativi}
\textbf{Criterio del Confronto} \\
Sia
$$\sum_{n=0}^{\infty}a_n<\infty$$
Se vale che definitamente $0\leq b_n\leq a_n$, allora
$$\sum_{n=0}^{\infty}b_n<\infty.$$
Eventualmente in combinazione con somme telescopiche, questo criterio prova la convergenza o divergenza di molte serie. Ad esempio da $\frac{1}{n^2}<\frac{1}{n(n-1)}$ segue 
$$ \sum_{n\geq 1}\frac{1}{n^2} = 1+\sum_{n\geq 2}\frac{1}{n^2} \leq 1+\sum_{n\geq 2}\left(\frac{1}{n-1}-\frac{1}{n}\right) = 2 $$
e un discorso analogo può essere applicato anche alla serie armonica generalizzata.\\

\textbf{Criterio del Confronto Asintotico} \\
È una forma più generale del precedente criterio. Se due successioni a termini non negativi $\{a_n\}_{n\geq 1}$ e $\{b_n\}_{n\geq 1}$ \\sono tali per cui $\lim_{n\to+\infty}\frac{a_n}{b_n}$ esiste finito, le serie 
$$ \sum_{n\geq 1} a_n,\qquad \sum_{n\geq 1} b_n $$
sono entrambe convergenti o entrambe positivamente divergenti.\\

\textbf{Criterio del Rapporto} \\
Sia
$$\sum_{n=0}^{\infty}a_n$$
una serie a termini mai nulli. Se si ha che:
$$\lim_{n\to\infty} \left|\frac{a_{n+1}}{a_n}\right|=c<1$$
allora la serie degli $a_n$ converge assolutamente.\\
È una conseguenza abbastanza immediata della definizione di limite e del criterio del confronto.\\ O, volendo, del criterio successivo, in quanto per il Lemma di Hadamard $\frac{|a_{n+1}|}{|a_n|}\to c$ comporta $\sqrt[n]{|a_n|}\to c$.\\

\textbf{Criterio della Radice} \\
Se $\{a_n\}_{n\geq 1}$ è una successione a valori non negativi tale per cui
$$ \lim_{n\to +\infty}\sqrt[n]{a_n} = c \in [0,1), $$
allora la serie $\sum_{n\geq 1}a_n$ converge.\\
È una conseguenza immediata del confronto con una serie geometrica convergente.

\subsubsection{Serie a termini di segno variabile}

\textbf{Criterio di Leibniz}\\
Se $\{a_n\}_{n\geq 0}$ è una successione decrescente a zero, la serie
$$ \sum_{n\geq 0} (-1)^n a_n $$
è convergente.\\
\begin{proof} Posto come di consueto $A_N=\sum_{n=0}^{N}a_n$, dalle ipotesi segue che $\{A_{2N}\}_{N\geq 0}$ è una successione decrescente mentre $\{A_{2N+1}\}_{N\geq 0}$ è una successione crescente. Poiché $A_{2N} > A_{2N+1}$ le due successioni sono entrambe convergenti, in quanto quella crescente è limitata dall'alto mentre quella decrescente è limitata dal basso. Inoltre i limiti di queste due successioni debbono coincidere, in quanto $A_{2N+1}-A_{2N}=a_{2n+1}$ converge a zero per ipotesi. Segue che l'intera successione delle somme parziali è convergente, ossia che la serie è convergente. 
\end{proof}


Una importante generalizzazione è data dal \textbf{Criterio di (Abel-)Dirichlet}.\\
Se $\{a_n\}_{n\geq 0}$ è una successione con somme parziali limitate e $\{b_n\}_{n\geq 0}$ è una successione decrescente a zero,\\ la serie $\sum_{n\geq 0}a_n b_n$ è convergente.

\emph{Sketch della dimostrazione}. Segue dall'identità
$$ \sum_{n=0}^{N}a_n b_n = A_N b_N - \sum_{n=0}^{N-1} A_n (b_{n+1}-b_n) $$
che è un analogo discreto della formula di integrazione per parti, nota come \textbf{formula di sommazione per parti}.\\ La sua dimostrazione è banale per induzione su $N$.\qed

Dalla formula di integrazione per parti segue l'omonimo criterio per gli integrali: se su $[0,+\infty)$ si ha che $f(x)$ ha primitiva limitata e $g(x)$ è decrescente a zero, $f(x)g(x)$ è impropriamente Riemann-integrabile su $\R^+$.

\subsection{Serie di Potenze}
Una serie di potenze (centrata nell'origine) è definita come:
$$\sum_{n=0}^{\infty}a_n x^n$$
con $x\in\C$, e sia il \textbf{Raggio di Convergenza} \\
$$\rho=\frac{1}{\limsup\sqrt[n]{|a_n|}}.$$
La serie di potenze converge puntualmente nella palla $B_0=\left\{z\in\C : |z|< \rho \right\}$ e uniformemente su ogni compatto contenuto in $B_0$.

\subsection{Metodi creativi per il calcolo esplicito}
Vediamo adesso come abusare della linearità delle Serie per calcolare esplicitamente una classe di queste. \\
Sia
$$S=\sum_{n\geq 0}^{}\frac{f(n)}{k^n}$$
con $k\in\N \wedge k\geq 2$.
Sarebbe molto comodo in questo caso ricondursi ad una serie geometrica.
Ipotizzando che esista una applicazione lineare e continua $T$ tale da mandare $x^n$ in $f(n)$ otteniamo:
$$S=\sum_{n\geq 0}\frac{f(n)}{k^n}=\sum_{n\geq 0}\frac{T(x^n)}{k^n}= T\left(  \sum_{n\geq 0}\left(\frac{x}{k}\right)^n \right)= T \left(\frac{1}{1-\frac{x}{k}}\right)$$ \\
in base alla scelta/costruzione di $T$ possiamo calcolare esplicitamente tute le serie di questo tipo.
(Possibili applicazioni lineari che farebbero al caso nostro sono: Derivazione, Integrazione, Somma, Prodotto, Valutazione e tutte le loro composizioni)\\
Un esempio di utilizzo di questo metodo è calcolare esplicitamente la serie:
$$\sum_{n\geq 0}^{}\frac{n^2}{4^n}$$
utilizzando come operatore $T$ la somma delle prime due derivate valutata in $1$ (esercizio per il lettore).\\
In generale questo metodo è utile ogni qual volta si sta trattando una Serie i cui termini, a meno di un fattore, coincidono con quelli di una serie che già sappiamo calcolare.\\
A onor del vero, per quanto potente è raro che tale metodo sia \emph{l'unico} in grado di esplicitare un'assegnata serie. 
Tornando all'esempio precedente, è ovvio che la serie presentata sia convergente, in quanto definitivamente $\frac{n^2}{4^n}\in\left(0,\frac{1}{3^n}\right]$. 
Sono allora lecite tutte le seguenti manipolazioni (basate unicamente su moltiplicazioni per $4$ e \emph{reindexing}):
$$ S=\sum_{n\geq 0}\frac{n^2}{4^n}=\sum_{n\geq 1}\frac{n^2}{4^n},\qquad 4S=\sum_{n\geq 1}\frac{n^2}{4^{n-1}}=\sum_{m\geq 0}\frac{(m+1)^2}{4^m}, $$

$$ 3S=4S-S = \sum_{n\geq 0}\frac{(n+1)^2-n^2}{4^n}=\sum_{n\geq 0}\frac{2n+1}{4^n}=1+\sum_{n\geq 1}\frac{2n+1}{4^n},$$

$$ 12S=4(3S) = 4+\sum_{n\geq 1}\frac{2n+1}{4^{n-1}} = 4+\sum_{m\geq 0}\frac{2m+3}{4^m}, $$

$$ 9S = 12S-3S = 4+\sum_{n\geq 0}\frac{(2n+3)-(2n+1)}{4^n} = 4+2\sum_{n\geq 0}\frac{1}{4^n} = 4+\frac{2}{1-\frac{1}{4}} = 4+\frac{8}{3} = \frac{20}{3} $$
dalle quali segue $S=\frac{20}{27}$.


\subsubsection{Criterio Cannonata}

Per il \textbf{Criterio di Convergenza Dominata} tutte Le serie che convergono \emph{abbastanza} velocemente commutano con l'integrale. All'atto pratico ciò comporta che, nelle ipotesi corrette, è lecito scrivere:
$$\sum_{n\geq 0}^{}\int_{a}^{b}f(x)dx =\int_{a}^{b}\sum_{n\geq 0}^{}f(x) dx.$$ 
Questo torna utile in quanto è moderatamente comune sostituire ad una funzione una sua \textbf{Rappresentazione integrale}.
(Non esattamente collegato, ma per farsi un'idea dell'utilità di questo fatto vedere l'esercizio \textbf{J17})
\subsection{Creative Telescoping}
Un metodo importante è quello di trasformare Serie apparentemente complesse in Serie Telescopiche o combinazioni lineari di serie telescopiche.
Tipicamente per questo tipo di lavoro bisogna farci l'occhio e sapere un po' dove mettere le mani, ma diventa abbastanza intuitivo velocemente.\\ (serve appunto un po' di creatività)\\

\section{Integrali Tricky e Metodi Interessanti}
Saranno date per note le principali tecniche di integrazione (per sostituzione e per parti), infatti, questo paragrafo si concentrerà nell'illustrare degli integrali più complessi e meritevoli di particolare attenzione, oltre che a tecniche di integrazione un po' più oscure. (Sono a conoscenza che questa sezione è meno utile delle precedenti, visto che è difficile che uno qualunque di questi esempi appaia esplicitamente in una prova. Ma sono comunque ad avviso mio e di Jack abbastanza importanti da avere a portata di mano in caso di necessità). alcune tecniche che verranno illustrate sono l'utilizzo della convergenza dominata (vedere paragrafo sui criteri delle serie), Integrali complessi, abuso di rappresentazioni integrali etc.
\subsection{Un primo Caso interessante}
$$\int_{0}^{\frac{\pi}{2}}(\cos \theta)^{2n}d\theta=\frac{\pi}{2\cdot4^n}\binom{2n}{n}$$
$$\int_{0}^{\frac{\pi}{2}}(\cos \theta)^{2n+1}d\theta= \frac{4^n}{(2n+1)\binom{2n}{n}}$$
inaspettatamente questi due integrali sono strettamente legati ai Binomiali Centrali e sono appunto una loro rappresentazione integrale.
\subsection{Decomposizione in fratti semplici}
L'integrazione di funzioni razionali (quozienti di polinomi) è puramente algoritmica, in quanto sempre riconducibile all'integrazione di funzioni della forma $\frac{1}{(x-\alpha)^n}$ (eventualmente con $\alpha\in\C$). Analizziamo la situazione attraverso un paio di esempi concreti.
\begin{ex} Si determini esplicitamente
$$ \int_{0}^{1}\frac{x^6}{(x+1)^2(x+2)(x^2+1)}\,dx $$ 
\end{ex}
\textbf{Soluzione}. Un primo step è ricondursi all'integrazione di $\frac{p(x)}{q(x)}$ dove $p(x),q(x)$ non hanno fattori comuni e $\deg p < \deg q$. Nel nostro caso il grado di $x^6$ supera di $1$ il grado di $(x+1)^2(x+2)(x^2+1)$, dunque 
$$ \frac{x^6}{(x+1)^2(x+2)(x^2+1)} = (Ax+B)+\frac{p(x)}{(x+1)^2(x+2)(x^2+1)}$$
dove $(Ax+B)$ è il quoziente e $p(x)$ è il resto della divisione tra $x^6$ e $(x+1)^2(x+2)(x^2+1)$. I coefficienti $A$ e $B$ possono essere determinati eseguendo la divisione in colonna, ricorrendo al Teorema cinese del resto o anche attraverso stratagemmi \emph{ad hoc}. Nel nostro caso possiamo ad esempio osservare che $x^6$ differisce di $1$ da un multiplo di $x^2+1$, via $x^6+1=(x^2+1)(x^4-x^2+1)$. Rappresentando $x^6$ come $(x^6+1)-1$ abbiamo pertanto 
$$ \frac{x^6}{(x+1)^2(x+2)(x^2+1)} = \frac{x^4-x^2+1}{(x+1)^2(x+2)}-\frac{1}{(x+1)^2(x+2)(x^2+1)}$$
e possiamo nuovamente osservare che $x^4-x^2$ è un multiplo di $x+1$, via $x^4-x^2=x^2(x-1)(x+1)$. Ciò conduce a 
$$ \frac{x^6}{(x+1)^2(x+2)(x^2+1)} = \frac{x^2(x-1)}{(x+1)(x+2)}+\frac{1}{(x+1)^2(x+2)}-\frac{1}{(x+1)^2(x+2)(x^2+1)}$$
da cui facilmente segue 
$$ \frac{x^6}{(x+1)^2(x+2)(x^2+1)} = (x-4)-\frac{2}{x+1}+\frac{12}{x+2}+\frac{1}{(x+1)^2(x+2)}-\frac{1}{(x+1)^2(x+2)(x^2+1)}.$$
L'integrazione su $[0,1]$ dei primi tre addendi del membro destro è immediata.\\ Il problema è così ricondotto alla determinazione di 
$$I_1=\int_{0}^{1}\frac{dx}{(x+1)^2(x+2)},\qquad I_2=\int_{0}^{1}\frac{dx}{(x+1)^2(x+2)(x^2+1)}.$$
Rammentiamo che $$\frac{1}{(n+a)(n+b)}=\frac{1}{b-a}\left(\frac{1}{n+a}-\frac{1}{n+b}\right),$$
da cui segue 
\begin{eqnarray*} \frac{1}{(x+1)^2(x+2)}&=&\frac{1}{x+1}\left(\frac{1}{x+1}-\frac{1}{x+2}\right)=\frac{1}{(x+1)^2}-\frac{1}{x+1}+\frac{1}{x+2}\end{eqnarray*}
che prova immediatamente $I_1=\frac{1}{2}-\log\left(\frac{4}{3}\right)$. Infine 
$$ \frac{1}{(x+1)^2(x+2)(x^2+1)}=\frac{C}{x+1}+\frac{D}{x+2}+\frac{E}{x+i}+\frac{F}{x-i}+\frac{G}{(x+1)^2}.$$
Con sufficiente pazienza i coefficienti $C,D,E,F,G$ possono essere determinati risolvendo un sistema lineare in $5$ equazioni e $5$ incognite. Ma anche se, come in un noto proverbio africano, \emph{Dio è lento e voi avete fretta}, le strategie abbondano. Il coefficiente $G$ può essere determinato moltiplicando ambo i membri per $(x+1)^2$ e poi considerando il limite per $x\to -1$: segue che $G=\frac{1}{2}$. Analogamente, moltiplicando ambo i membri per $(x+2)$ e considerando il limite per $x\to -2$ abbiamo $D=\frac{1}{5}$. I coefficienti $E,F$ sono necessariamente coniugati, per cui da $F=\lim_{x\to i}(x-i)f(x)=-\frac{1}{10}+\frac{i}{20}$ discende $E=-\frac{1}{10}-\frac{i}{20}$. Infine, poiché moltiplicando ambo i membri per $x$ e considerando il limite per $x\to +\infty$ si ottiene $0$, $C+D+E+F=0$, da cui $C=0$. In conclusione 
$$ \frac{1}{(x+1)^2(x+2)(x^2+1)} = \frac{1}{5}\cdot\frac{1}{x+2}-\frac{1}{10}\cdot\frac{1}{x^2+1}-\frac{1}{5}\cdot\frac{x}{x^2+1}+\frac{1}{2}\cdot\frac{1}{(x+1)^2} $$
che comporta $I_2=\frac{1}{40}\left(10-\pi+8\log 3-12\log 2\right)$ e 
$$ \int_{0}^{1}\frac{x^6\,dx}{(x+1)^2(x+2)(x^2+1)}=\frac{1}{40}\left(\pi-130-628\log 2+512\log 3\right).\qed $$
\begin{ex} Si determini esplicitamente il valore dell'integrale 
$$ I=\int_{0}^{1}\frac{dx}{(x^2+1)(x^2+3)}. $$
\end{ex}
\textbf{Soluzione}. Analogamente a prima potremmo determinare i \emph{residui} di $f(x)=\frac{1}{(x^2+1)(x^2+3)}$ in corrispondenza di $x=\pm i$ e $x=\pm i\sqrt{3}$, ma possiamo anche solo constatare che 
$$ \frac{1}{(x^2+1)(x^2+3)} = \frac{1}{2}\left(\frac{1}{x^2+1}-\frac{1}{x^2+3}\right) $$
da cui, immediatamente:
$$ I = \frac{1}{2}\int_{0}^{1}\frac{dx}{x^2+1}-\frac{1}{2}\int_{0}^{1}\frac{dx}{x^2+3}=\frac{\pi}{8}-\frac{1}{2\sqrt{3}}\int_{0}^{1/\sqrt{3}}\frac{dz}{z^2+1} = \frac{\pi}{8}-\frac{\pi}{12\sqrt{3}}.\qed$$

La decomposizione in fratti semplici è utile non solo nel contesto dell'integrazione di funzioni razionali, ma anche nell'approssimazione numerica (o nel calcolo esplicito) di serie.

\begin{ex} Si determini esplicitamente 
$$ S=\sum_{n\geq 1}\frac{1}{n(n+1)(n+4)}.$$
\end{ex}
\textbf{Soluzione}. La decomposizione in fratti semplici di $f(x)=\frac{1}{x(x+1)(x+4)}$ può essere ottenuta come segue:
$$ f(x)=\frac{1}{x+4}\left(\frac{1}{x}-\frac{1}{x+1}\right) = \frac{1}{4}\left(\frac{1}{x}-\frac{1}{x+4}\right)-\frac{1}{3}\left(\frac{1}{x+1}-\frac{1}{x+4}\right) $$
e ciò comporta immediatamente 
$$ S = \frac{1}{4}\sum_{n\geq 1}\left(\frac{1}{n}-\frac{1}{n+4}\right)-\frac{1}{3}\sum_{n\geq 1}\left(\frac{1}{n+1}-\frac{1}{n+4}\right) = \frac{H_4}{4}-\frac{H_4-1}{3} = \frac{1}{3}-\frac{H_4}{12} = \frac{23}{144}.\qed$$
\textbf{Soluzione alternativa}. A partire da 
$$ \sum_{n\geq 1}\frac{x^{n+3}}{n(n+1)} = x^3+x^2(1-x)\log(1-x), $$
valida per ogni $x\in(-1,1)$, integrando ambo i membri su $(0,1)$ otteniamo 
$$ S = \frac{1}{4}+\int_{0}^{1}x^2(1-x)\log(1-x)\,dx = \frac{1}{4}+\int_{0}^{1}(1-z)^2 z \log(z)\,dz  $$
e per integrazione per parti 
$$ S = \frac{1}{4}+\left[\left(\frac{z^2}{2}-\frac{2z^3}{3}+\frac{z^4}{4}\right)\log z\right]_{0}^{1}-\int_{0}^{1}\left(\frac{z}{2}-\frac{2z^2}{3}+\frac{z^3}{4}\right)\,dz=\frac{1}{4}-\frac{1}{4}+\frac{2}{9}-\frac{1}{16} = \frac{23}{144}.\qed$$

\section{Equazioni Differenziali}
Per il Teorema Fondamentale del Calcolo Integrale (T.F.C.I.) possiamo risalire alla funzione $u(t)$ se se ne conosce la derivata, infatti l'equazione $$u'(t)=f(t)$$ ha soluzione $$u(t)=\int_{a}^{t}f(s)ds$$
In generale, data una funzione di due variabili $f(t,u)$ possiamo porci il problema di trovare una funzione $u(t)$ che verifichi l'equazione differenziale:$$u'(t)=f(t,u(t))$$
l'equazione di sopra si dice del primo ordine perché coinvolge solo la derivata prima della funzione $u(t)$.
\subsection{ED a Variabili Separabili}
si chiamano così le equazioni del tipo: $$u'(t)=a(t)f(u(t))$$ per risolvere queste equazioni basta dividere entrambi i membri per $f(u)$ ed integrare: $$\int\frac{u'(t)}{f(u(t))}dt=\int a(t)dt$$
\subsection{ED Lineari del Primo ordine}
sono le equazioni del tipo: $$u'(t)=a(t)u(t)+b(t)$$
con $a(t)$ e $b(t)$ funzioni date.\\
Indichiamo con $A(t)=\int a(t)dt$ si ha che, se $b(t)=0$ $$log(u(t))=A(t)+p$$ con p costante arbitraria.\\
quindi $$u(t)= ce^{A(t)}$$
con $c=e^p$ costante arbitraria
\subsection{Esempi}
\subsubsection{Decadimento Radioattivo}
è il processo secondo il quale un sostanza radioattiva decade, trasformandosi in un'altra sostanza più leggera a causa della perdita di neutroni.\\
Il carattere fondamentale di questa reazione è che non si può predire quando avverà, ma si può dare una probabilità a questo evento. Questa probabilità è $pdt$ proporzionale all'intervallo di tempo $dt$, indicando con $n(t)$ il numero di neutroni presenti al tempo $t$ tra $t$ e $t*dt$ se ne disintegreranno $n(t)pdt$. Il numero complessivo di neutroni diminuirà, ottendo quindi:$$\frac{n(p+dt)-n(t)}{dt}=-pn(t)$$
facendo tendere $dt$ a $0$ otteniamo: $$n'(t)=n_0e^{-pt}$$\\
il numero di neutroni decresce quindi esponenzialmente e si denota con $\tau=\frac{log2}{p}$ il tempo di dimezzamento
\subsubsection{Oscillatore Armonico}
Con questo termine si indica un sistema costituito da un punto materiale di massa $m$ che si muove su una rett, soggette ad una forza di richiamo, proporzionale alla distanza dal punto $0$. \\
indicando con $u(t)$ la posizione del corpo al tempo $t$, la forza totale che agisce sul corpo sarà: $f=-ku-hu'$ e l'equazione del moto $f=ma$ si scrive: $$mu''(t)+hu'(t)+ku(t)=0$$\\
ponendo $\omega_0^2=\frac{k}{m}$ e $a=\frac{h}{2m}$.\\
$$u''(t)+2au'(t)+\omega_0^2u=0$$ \\
se cerchiamo soluzioni della forma $e^{\lambda t}$ otteniamo l'equazione $\lambda^2 + \omega_0^2=0$ che ha radici complesse $i\omega_0t$ e $-i\omega_0t$ che corrispondono alle soluzioni : $e^{i\omega_0t}$ e $e^{-i\omega_0t}$\\
dove  $e^{i\omega_0t}$ e $e^{-i\omega_0t}$ stanno per $cos\omega_0t+isen\omega_0t$ e $cos\omega_0t-isen\omega_0t$ \\
La soluzione generale della differenziale è quindi: $$u(t)=c_1sen\omega_0t+c_2cos\omega_0t$$\\
\subsection{Metodi di Risoluzione di ED non omogenee}
In generale consideriamo $\Tilde{x_{OM}}$ la soluzione dell'omogenea. Allora la soluzione generale sarà del tipo: $$\Tilde{x}= \Tilde{x_{OM}}+ \Tilde{x_1}$$\\
dove $\Tilde{x_1}$ è la soluzione generale dell'equazione differenziale.\\
Per trovarla è utile il \textbf{Metodo di Somiglianza} che consiste nel cercare le soluzioni generali a partire dal termine noto dell'equazione.\\
Se per esempio stiamo cercando di risolvere l'equazione:
$$u'(t)+2u(t)=t^2$$
Cerchiamo prima la base delle soluzione dell'omogenea:$$u'(t)+2u(t)=0\Rightarrow \lambda +2 =0 \Rightarrow \lambda=-2 \Rightarrow \Tilde{x_{OM}}=e^{-2t}$$
Per trovare la soluzione generale dell'equazione ora guardiamo il termine noto $t^2$, la speranza è quella di trovare come soluzioni una funzione della stessa forma di $t^2$ in questo caso, cerchiamola tra i polinomi.\\
Supponiamo quindi che $\Tilde{x_1}=at^3+bt^2+ct+d$ sia una soluzione, allora derivando otteniamo: $\Tilde{x_1}'=3at^2+2bt+c$, utilizzando la relazione data dalla differenziale sappiamo che:
$$3at^2+2bt+c + 2at^3+2bt^2+2ct+2d=t^2\Leftrightarrow 3a+2a=1\Rightarrow a=\frac{1}{5}$$
La soluzione totale è quindi $\Tilde{x}= c_1e^{-2t}+c_2\frac{1}{5}t^3$\\
Un altro metodo per risolvere alcune differenziali (più difficili delle precedenti) è quello di studiare il comportamento di $u'(t)$ con la sua inversa $v'(t)$, se esiste, o analogamente, se è ben definito, col suo reciproco.
\section{Esercizi e simulazioni di pre-test}
Gli esercizi di seguito riportati con una stella ($\star$) hanno difficoltà paragonabile a quelli del compito, quelli riportati con due stelle ($\star\star$) sono più impegnativi. Quelli con tre stelle ($\star\star\star$) sono estremamente impegnativi, si raccomanda cautela.\\


 \textbf{J1}($\star$). Si dimostri che 
\begin{equation*}
 \sum_{n\geq 1}\frac{1}{5^n}\binom{2n}{n}   
\end{equation*}
è una serie convergente.


\textbf{J2}($\star$). Si determini il valore del seguente integrale: 
\begin{equation*}
 \int_{0}^{+\infty}\frac{\ln t}{1+t^2}\,dt   
\end{equation*}


\textbf{J3}($\star$). Si dimostri che per qualunque $k\in\mathbb{N}$ la serie

 \begin{equation*}
    a_k = \sum_{n\geq 1}\frac{n^k}{2^n} 
 \end{equation*}
converge ad un numero naturale.  \par
$(\star\star\star)$ Si provi che 
\begin{equation*}
    a_k\sim \frac{k!}{\ln(2)^{k+1}}
\end{equation*} quando $k\to +\infty$.


\textbf{J4}$(\star)$. Si dimostri che il seguente limite esiste ed è finito:

$$ \lim_{N\to +\infty}\left(-2\sqrt{N}+\sum_{n=1}^{N}\frac{1}{\sqrt{n}}\right).$$

\textbf{J5}$(\star)$. Si approssimi il valore della seguente serie convergente con un errore non superiore al millesimo:
$$ \sum_{n\geq 1}\left(1-\cos\frac{1}{n}\right)$$

\textbf{J6}$(\star)$. Per ogni $n\in\mathbb{N}^+$ il polinomio $P_n(x)$ è definito come segue:
$$ P_n(x) = \frac{1}{n!}\cdot\frac{d^n}{dx^n}\left(x(x-1)\right)^n.$$
Si dimostri che $P_n(x)$ ha $n$ radici reali distinte nell'intervallo $(0,1)$ e si determini, al variare di $n$,\\ la somma dei quadrati di tali radici.

\textbf{J7}$(\star\star)$. Si dimostri che per qualunque numero reale $c$ esiste una funzione biunivoca $f:\mathbb{N}^+\to\mathbb{N}^+$ tale che 
$$ \sum_{n\geq 1}\frac{\sin(f(n))}{\sqrt{f(n)}} = c.$$

\textbf{J8}$(\star\star)$. La successione $\{a_n\}_{n\geq 0}$ è definita tramite $a_n=\int_{0}^{\pi/2}\left(\sin\theta\right)^n\,d\theta$.\\ Si dimostri che è decrescente a zero e che soddisfa $a_{n+1}^2 < a_n a_{n+2}$ per ogni $n\in\mathbb{N}$.

\textbf{J9}$(\star\star)$. Si dimostri che 
$$ f(x) = \int_{2x}^{3x}\frac{t\,dt}{\arctan t} $$
definisce una funzione positiva, crescente e convessa su $\mathbb{R^+}$. \\

\textbf{J10}$(\star\star)$. Data $f:\mathbb{R}\to\mathbb{R}$ definita da
$$ f(x) = \left\{\begin{array}{ccl}0 & \text{se} &x=0\\\frac{x^2}{\arctan x}&\text{se}& x\neq 0\end{array}\right.$$
si provi che essa è biunivoca e di classe $C^{\infty}$ (ossia derivabile con continuità infinite volte) e che lo stesso vale per la sua funzione inversa $f^{-1}(x)$. Si determini infine la derivata terza nell'origine di $f^{-1}(x)$ e il valore dell'integrale
$$ \int_{0}^{4/\pi}f^{-1}(x)\arctan^2(f^{-1}(x))\,dx.$$

\textbf{J11}$(\star)$. [Integrale di Frullani] Si dimostri che per ogni $a\in\mathbb{R}^+$ si ha, in senso di Riemann improprio,
$$ \int_{0}^{+\infty}\frac{e^{-x}-e^{-ax}}{x}\,dx = \log a.$$

\textbf{J12}$(\star\star)$. Si dimostri che la successione $\{a_n\}_{n\geq 0}$ definita da
$$ a_n = \sum_{k=0}^{n}\binom{n+k}{k}\binom{n}{k}\frac{(-1)^k}{(k+1)(k+2)(k+3)} $$
è definitivamente nulla.

\textbf{J13}$(\star\star)$. Si determini il comportamento asintotico (per $n\to +\infty$) della successione $\{a_n\}_{n\geq 0}$ definita attraverso

$$ a_n = \int_{0}^{\pi/4}\left(1+\tan\theta\right)^n\,d\theta. $$

\textbf{J14}$(\star\star\star)$. Si provi che il seguente limite esiste finito e se ne determini il valore:
$$ \lim_{x\to 1^-}\left(\sqrt{1-x}\sum_{n\geq 0}x^{n^2}\right).$$

\textbf{J15}$(\star)$. Si determini la derivata decima nell'origine della funzione $f(x)=\log^2(1-x)$.

\textbf{J16}$(\star\star)$. Si determini lo sviluppo di Taylor della funzione $f(x)=\arctan x$ centrato nel punto $1$ e si dimostri che,\\ più in generale, lo sviluppo di Taylor centrato in $x_0\in\mathbb{R}$ ha raggio di convergenza 
$$ \rho_{x_0} = \sqrt{1+x_0^2}. $$

{\label{J17}\textbf{J17}}$(\star)$ [Disuguaglianza di Huygens] Si dimostri che per ogni $\theta\in\left(0,\frac{\pi}{2}\right)$ vale
$$ 2\sin\theta + \tan\theta > 3\theta.$$

\textbf{J18}$(\star\star)$ $\{a_n\}_{n\geq 0}$ è una successione per ricorrenza definita attraverso $a_0=2$ e $a_{n+1}=\sqrt{a_n^4-2}$.\\ Si dimostri che la successione diverge positivamente ma la distanza tra $a_n$ e l'intero più vicino tende a zero.

\textbf{J19}$(\star)$. Si dimostri che tra tutti i triangoli di perimetro assegnato, quelli equilateri hanno area massima. 

\textbf{J20}$(\star\star)$. $ABCD$ è un quadrilatero convesso nel piano e i suoi lati misurano nell'ordine $4,5,6,7$. Si determini quanto può valere al massimo l'area di $ABCD$ e si dimostri che le configurazioni che massimizzano l'area sono tutte e sole quelle in cui $ABCD$ è ciclico, ossia ha vertici che giacciono su una circonferenza.

\textbf{J21}$(\star\star\star)$ (Bernstein). Si determini il valore del seguente limite: 
$$ \lim_{n\to +\infty} \frac{1}{e^n}\sum_{k=0}^{n}\frac{n^k}{k!}.$$
\textbf{J22}$(\star\star)$. Si determini se esiste o meno una funzione $f\in C^0((0,1))$ tale per cui
$$ \forall n\in\mathbb{N}^+,\quad \int_{0}^{1} x^n f(x)\,dx = \frac{1}{\sqrt{n}}. $$

\textbf{J23}$(\star\star)$. $\{a_n\}_{n\geq 0}$ è una successione per ricorrenza definita attraverso
$$ a_0=\alpha,\qquad a_{n+1} = \frac{1}{2}\left(a_n+n^2\right).$$
Si determinino gli $\alpha\in\mathbb{R}$ tali per cui $a_{69}$ è strettamente più piccolo di qualunque altro elemento della successione. 

\textbf{J24}$(\star\star\star)$. Per ogni $n\in\mathbb{N}$ definiamo $d_n$ come la derivata di ordine $4n+1$ nell'origine della funzione $f(x)=\tan x$.\\ Si dimostri che per ogni $n\in\mathbb{N}^+$ si ha $d_n \in 10\mathbb{N}+6$.

\textbf{J25}$(\star\star)$. Per ogni $n\in\mathbb{N}^+$ poniamo $p_n(x)=1-x-x^n$. Si dimostri che $p_n(x)$ ha un'unica radice reale $\xi_n\in (0,1)$\\ e si determini il comportamento asintotico di $\xi_n$ per $n\to +\infty$. 

\textbf{J26}$(\star)$ Si determini l'insieme dei $\kappa\in\mathbb{R}$ tali per cui il polinomio $4x^3-\kappa x+1$ ha tre radici reali distinte.

\textbf{J27}$(\star\star)$ Si provi che il seguente limite esiste finito e se ne determini esplicitamente il valore:
$$ \lim_{n\to +\infty} \sqrt{n}\left(\frac{4}{27}\right)^n \binom{3n}{n}. $$

\textbf{J28}$(\star\star)$ (Demidovic) Si risolva l'equazione differenziale $(x-y)y'=y^2$.

\textbf{J29}$(\star\star)$ (Una sorta di problema di Keplero) Si dimostri che esiste un unico $\alpha > 1$ tale per cui la lunghezza del grafico di $f(x)=x^{\alpha}$ sull'intervallo $[0,1]$ è esattamente pari a $\frac{3}{2}$. Si stimi poi il valore di tale $\alpha$ con un errore non superiore al centesimo.

\textbf{J30}$(\star\star)$ Si discuta la convergenza della serie $\sum_{n\geq 1}\frac{\sin(n(n+1))}{n}$. 

\textbf{J31}$(\star\star)$ (Approssimazione di Ramanujan dei poveri) Detto $L(a,b)$ il perimetro di una ellisse di semiassi $a,b > 0$,\\ si dimostri che 
$$ \frac{L(a,b)}{2\pi}\in\left[\frac{a+b}{2},\sqrt{\frac{a^2+b^2}{2}}\right]. $$

\textbf{J32}$(\star\star\star)$ (Somme di Ramanujan, stavolta per davvero) Detto $\Phi_n(x)$ l'$n$-esimo polinomio ciclotomico, 
$$\Phi_n(x) = \prod_{\substack{1\leq k\leq n\\\gcd(k,n)=1}}\left(x-\exp\left(\frac{2\pi i k}{n}\right)\right),$$ e detta $\varphi$ la funzione totient di Eulero, $\varphi(n)=\#\left\{k:1\leq k\leq n, \gcd(k,n)=1\right\}$, si determini al variare di $n\in\mathbb{N}^+$\\ il coefficiente di $x^{\varphi(n)-2}$ in $\Phi_n(x)$.

\textbf{J33}$(\star)$ Si dimostri che non tutte le funzioni impropriamente Riemann-integrabili sull'intervallo $(0,1)$ realizzano l'uguaglianza
$$ \int_{0}^{1}f(x)\,dx = \lim_{N\to +\infty}\frac{1}{N}\sum_{k=1}^{N}f\left(\frac{k}{N}\right).$$

\textbf{J34}$(\star\star\star)$ (Ramanujan once again) Si dimostri l'identità
$$ 2\pi\sum_{n\geq 0}\left(\sqrt{n+1}-\sqrt{n}\right)^3 = 3\sum_{n\geq 1}\frac{1}{n\sqrt{n}}.$$

\textbf{J35}$(\star)$ Si dimostri che per ogni $x\in\mathbb{R}$ vale

$$ \sqrt{x^2+(x-1)^2}+\sqrt{(x-7)^2+(x-8)^2}\geq 10 $$

e si determini se ci sono $x$ per cui vale l'uguaglianza.

\textbf{J36}$(\star)$ Si dimostri che il seguente limite esiste finito e se ne determini il valore:
$$ \lim_{N\to +\infty}\sqrt[N]{\sum_{k=0}^{N}\binom{N}{k}\frac{k^2}{2^k}}.$$

\textbf{J37}$(\star)$ Si dimostri che il seguente limite esiste finito e se ne determini il valore:
$$ \lim_{x\to +\infty} \left(-2^x+\sqrt{4^x+2^x+x^2}\right) $$

\textbf{J38}$(\star)$ Si determini la derivata quarta nell'origine della funzione $f(x)=\cos(1-\cos x)$.

\textbf{J39}$(\star)$ Si determini il valore del seguente integrale:
$$ \int_{0}^{1}\sin^2(\arctan(\cos(\arcsin x))))\,dx $$ 

\textbf{J40}$(\star\star)$ Jack lancia una moneta equa per infinite volte e pone $a_n=1$ se l'esito dell'$n$-esimo lancio è una testa, $a_n=-1$ se l'esito dell'$n$-esimo lancio è una croce. Si dimostri che quasi certamente (ossia con probabilità $1$) la serie $\sum_{n\geq 1}\frac{a_n}{n}$ è convergente.

\textbf{J41}$(\star)$ Si dimostri che per ogni $\lambda\in\mathbb{R}$ l'equazione $x^2-\sin(x)\sinh(x)=\lambda$ ammette infinite soluzioni reali.

\textbf{J42}$(\star)$ Si determini qual è il più grande esponente $\alpha\in\mathbb{R}$ per cui si ha
$$ \cos(x)\leq\left(1-\frac{4x^2}{\pi^2}\right)^\alpha $$
per ogni $x\in\left[0,\frac{\pi}{4}\right]$.

\textbf{J43}$(\star)$ Si determini il valore del seguente integrale:
$$ I=\int_{0}^{+\infty}\left|\sin x\right| e^{-x}\,dx $$

\textbf{J44}$(\star\star)$ Considerata la successione per ricorrenza definita da $a_0=\sqrt{2}$ e $a_{n+1}=|2a_n-3|$, di dimostri che per ogni $n\in\mathbb{N}$ si ha che $a_n$ è un numero irrazionale appartenente all'intervallo $[0,3]$ e che $\{a_n\}_{n\geq 0}$ non ammette limite.

\textbf{J45}$(\star\star)$ $f:[0,+\infty)\to\mathbb{R}$ è definita come l'unica soluzione di $f''(x)=x\cdot f(x)$ che soddisfa $f(0)=1$ e $f'(0)=0$.\\ Si dimostri che 
$$ \lim_{x\to +\infty}\frac{\log f(x)}{x\sqrt{x}} = \frac{2}{3}.$$

\textbf{J46}$(\star)$ Si dimostri che per qualunque $\alpha > 1$ l'integrale $\int_{0}^{+\infty}\sin(x^\alpha)\,dx $ è convergente nel senso di Riemann improprio.

\textbf{J47}$(\star)$ Si determini per quali $\alpha\in\mathbb{R}^+$ la seguente serie converge:
$$ \sum_{n\geq 1}\frac{\binom{2n}{n}}{n^\alpha 4^n} $$

\textbf{J48}$(\star)$ Si dimostri che per ogni $n\in\mathbb{N}$ si ha
$$ \sum_{k=0}^{n}\binom{2k}{k}\binom{2n-2k}{n-k} = 4^n $$

\textbf{J49}$(\star\star)$ La successione $\{a_n\}_{n\geq 0}$ è definita da $a_0=69$ e $a_{n+1}=\log(a_n+1)$.<br> Si provi che $\lim_{n\to +\infty} na_n$ esiste finito e lo si determini esplicitamente. 

\textbf{J50}$(\star)$ Si determini sotto quali condizioni per $\alpha,\beta\in\mathbb{R}^+$ si ha che la serie
$$ \sum_{n\geq 0}\left((n+1)^\alpha-n^\alpha\right)^\beta $$
risulta convergente.

\textbf{J51}$(\star\star)$ Si dimostri che il seguente integrale è convergente e se ne determini esplicitamente il valore:
$$ \int_{0}^{+\infty}\left(\sqrt[3]{x+1}-\sqrt[3]{x}\right)^3\,dx $$

\textbf{J52}$(\star)$ Si determini esplicitamente il valore del seguente integrale e se ne deducano approssimazioni razionali per $e$: $$\int_{0}^{1}x^4(1-x)^4 e^{-x}\,dx. $$

\textbf{J53}$(\star)$ Si determini il polinomio $p(x)\in\mathbb{R}[x]$ di minimo grado il cui grafico ha tutte le seguenti proprietà:
\begin{itemize}
\item passa dall'origine e la retta tangente nell'origine ha pendenza $2$
\item passa da $(1,3)$ ed ha in tal punto un massimo relativo
\item passa da $(3,1)$ ed ha in tal punto un minimo relativo
\item passa da $(4,4)$ e in tal punto la retta tangente ha pendenza $4$.
\end{itemize}
\textbf{J54}$(\star\star)$ Sul compatto $K=\{(x,y,z)\in\mathbb{R}^3: x,y,z\in[0,1], x+y+z\leq 1\}$ si determinino la più grande costante $\alpha$ e la più piccola costante $\beta$ per cui
$$\alpha (x^3+y^3+z^3)^2\leq  (x^2+y^2+z^2)^3 \leq \beta (x^3+y^3+z^3)^2$$
valga per ogni $(x,y,z)\in K$.

\textbf{J55}$(\star\star)$ (Rudin) Nell'ipotesi che $\sum_{n\geq 0}a_n$ sia una serie convergente a termini positivi e decrescenti, si dimostri che esiste una successione $\{b_n\}_{n\geq 0}$ positiva, crescente e illimitata tale che $\sum_{n\geq 0}a_n b_n$ è ancora convergente.

\textbf{J56}$(\star)$ Dato un triangolo acutangolo $ABC$ nel piano, si dimostri che esiste un unico punto $P$ che minimizza la quantità $PA+PB+PC$, e che tale punto verifica $\widehat{APB}=\widehat{BPC}=\widehat{CPA}$.

\textbf{J57}$(\star)$ Tra tutti i cilindri circolari retti di assegnato volume, si determinino le proporzioni di quelli che hanno superficie minima.

\textbf{J58}$(\star)$ Si determini esplicitamente la distanza nel piano cartesiano tra il punto di coordinate $(1,0)$ e la parabola di equazione $y=x^2$.

\textbf{J59}$(\star)$ Si dimostri che la seguente serie è convergente e se ne determini esplicitamente il valore:
$$\sum_{n\geq 1}\left(\frac{1}{4n-1}+\frac{1}{4n-3}-\frac{1}{2n}\right).$$

\textbf{J60}$(\star\star)$ Due barche, $A$ e $B$, sono inizialmente attraccate a una certa distanza l'una dall'altra lungo un tratto rettilineo di costa. Le due barche prendono a muoversi simultaneamente e procedono entrambe con velocità di modulo costante, ma
\begin{itemize}
\item $A$ procede di moto rettilineo lungo una semiretta perpendicolare alla costa
\item $B$ procede inseguendo $A$, ossia $\vec{v}_B$ ha a qualunque tempo $t>0$ la stessa direzione del vettore $A-B$.
\end{itemize}
Si dimostri che per $t\to +\infty$ la distanza tra le due barche converge a metà della distanza iniziale.  

\textbf{J61}$(\star)$ Sapendo che $\sum_{n\geq 1}\frac{1}{n^2}=\frac{\pi^2}{6}$ si determini esplicitamente
$$ S = \sum_{n\geq 0}\frac{1}{(2n+1)^2 (2n+3)^2 (2n+5)^2} $$

\textbf{J62}$(\star)$ Si dimostri che 
$$ \int_{0}^{\pi/2}\cos(\cos x)\,dx > \frac{6}{5}.$$

\textbf{J63}$(\star)$ Si dimostri che per qualunque polinomio $p(x)\in\mathbb{R}[x]$ di grado $\leq 3$ si ha 

$$ \int_{a}^{b} p(x)\,dx = \frac{b-a}{6}\left(p(a)+4\cdot p\left(\frac{a+b}{2}\right)+p(b)\right). $$

\textbf{J64}$(\star\star)$ $f:\mathbb{Z}\times\mathbb{Z}\to (0,1)$ è una funzione che realizza
$$ f(m,n) = \frac{1}{4}\left(f(m+1,n)+f(m-1,n)+f(m,n-1)+f(m,n+1)\right) $$
per ogni $m,n\in\mathbb{Z}$. Si dimostri che $f$ è necessariamente costante.

\textbf{J65}$(\star)$ Una successione per ricorrenza $\{a_n\}_{n\geq 0}$ è definita attraverso $a_0=1$ e 
$$ a_n = 2 a_{n-1} + 4 a_{n-2} + 8 a_{n-3}+\ldots 2^n a_{0}.$$
Si determini un'espressione esplicita per $a_n$.

\textbf{J66}$(\star\star)$ Detto $\mathcal{P}$ l'insieme dei numeri primi, si dimostri che 
$$ \sum_{p\in\mathcal{P}}\frac{1}{p^2} \leq \log\sqrt{\frac{5}{2}}.$$

\textbf{J67}$(\star)$ Posto $H_n=\sum_{k=1}^{n}\frac{1}{k}$ si determini esplicitamente
$$ \sum_{n=1}^{N} n H_n. $$

\textbf{J68}$(\star\star)$(Shafer-Fink) Si provi che per ogni $x\in\mathbb{R}^+$ vale 
$$ \frac{3x}{1+2\sqrt{1+x^2}} < \arctan x < \frac{\pi x}{1+2\sqrt{1+x^2}} $$ 
e che per ogni $x> 1$ vale
$$ \log(x) > \frac{6(x-1)}{1+x+4\sqrt{x}}. $$

\textbf{J69}$(\star\star)$ $H^{(n)}$ è una matrice simmetrica e reale di dimensione $n$ che realizza $H_{ij}^{(n)}=\frac{1}{i+j-1}$.\\ Si determini esplicitamente $\det H^{(n)}$ in funzione di $n$, eventualmente osservando che
\begin{itemize}
\item $\frac{1}{i+j-1}=\int_{0}^{1}x^{i-1}\cdot x^{j-1}\,dx = \langle x^{i-1}, x^{j-1}\rangle $
\item l'ultima riga, privata dell'ultimo elemento, è necessariamente combinazione lineare delle precedenti righe private dell'ultimo elemento
\item i coefficienti di tale combinazione lineare sono fissati dalla risoluzione di un problema di interpolazione 
\item per l'invarianza del determinante sotto mosse di Gauss, la risoluzione del precedente problema esplicita il rapporto tra $\det H^{(n)}$ e $\det H^{(n-1)}$.
\end{itemize}

Infine tre simulazioni di pre-test, con soluzioni allegate:\\

\textbf{Simulazione di pre-test \#1}, \url{https://mathb.in/76160}, soluzioni presso \url{https://mathb.in/76167}\\
\textbf{Simulazione di pre-test \#2}, \url{https://mathb.in/76170}, soluzioni presso \url{https://mathb.in/76175}\\
\textbf{Simulazione di pre-test \#3}, \url{https://mathb.in/76189}, soluzioni presso \url{https://mathb.in/76190}


\newpage

\subsection{Soluzioni}
Segue un elenco delle soluzioni dei precedenti esercizi. Tra parentesi sono indicati trucchi o tecniche specifiche impiegati.\\

Soluzione del \textbf{J1}($\star$): \url{https://mathb.in/75940} (OGF dei binomiali centrali normalizzati)\\
Soluzione del \textbf{J2}($\star$): \url{https://mathb.in/75941} \\
Soluzione del \textbf{J3}($\star$): \url{https://mathb.in/75942} (Snake Oil per la parte difficile)\\
Soluzione del \textbf{J4}($\star$): \url{https://mathb.in/75944} (Hermite-Hadamard)\\
Soluzione del \textbf{J5}($\star$): \url{https://mathb.in/75945} \\
Soluzione del \textbf{J6}($\star$): \url{https://mathb.in/75946} (Formule di Viète e Newton, accenno ai polinomi di Legendre)\\
Soluzione del \textbf{J7}($\star\star$): \url{https://mathb.in/75939} (Riemann-Dini, sommazione per parti) \\
Soluzione del \textbf{J8}($\star\star$): \url{https://mathb.in/75947} (Cauchy-Schwarz)\\
Soluzione del \textbf{J9}($\star\star$): \url{https://mathb.in/75951} (Lemmi sulla convessità) \\
Soluzione del \textbf{J10}($\star\star$): \url{https://mathb.in/75971} (Proprietà dello sviluppo di Maclaurin di $\tan x$)\\
Soluzione del \textbf{J11}($\star$): \url{https://mathb.in/75958} \\
Soluzione del \textbf{J12}($\star\star$): \url{https://mathb.in/75972} (Rappresentazioni integrali, polinomi di Legendre)\\
Soluzione del \textbf{J13}($\star\star$): \url{https://mathb.in/75957} \\
Soluzione del \textbf{J14}($\star\star\star$): \url{https://mathb.in/75984} (Problema del cerchio di Gauss, un lemma di Analisi complessa)\\
Soluzione del \textbf{J15}($\star$): \url{https://mathb.in/75968} \\
Soluzione del \textbf{J16}($\star\star$): \url{https://mathb.in/75978} \\
Soluzione del \textbf{J17}($\star$): \url{https://mathb.in/75970} (AM-GM)\\
Soluzione del \textbf{J18}($\star\star$): \url{https://mathb.in/75977} (Polinomi di Chebyshev del primo tipo)\\
Soluzione del \textbf{J19}($\star$): \url{https://mathb.in/75998} (Principio di dualità) \\
Soluzione del \textbf{J20}($\star\star$): \url{https://mathb.in/76021} \\
Soluzione del \textbf{J21}($\star\star\star$): \url{https://mathb.in/75996} (Formula di Taylor con resto integrale, stime di momenti)\\
Soluzione del \textbf{J22}($\star\star$): \url{https://mathb.in/76009} (Trasformata di Laplace)\\
Soluzione del \textbf{J23}($\star\star$): \url{https://mathb.in/76024} (Manipolazioni di OGF, convessità)\\
Soluzione del \textbf{J24}($\star\star\star$): \url{https://mathb.in/76001} (ED non lineari, manipolazioni di EGF) \\
Soluzione del \textbf{J25}($\star\star$): \url{https://mathb.in/76016} (Metodo di Newton, funzione di Lambert)\\
Soluzione del \textbf{J26}($\star$): \url{https://mathb.in/76011} (AM-GM, polinomi di Chebyshev del primo tipo) \\
Soluzione del \textbf{J27}($\star\star$): \url{https://mathb.in/75999} (Integrali della forma $\int_{0}^{1}x^a(1-x)^b\,dx$, stime di momenti)\\
Soluzione del \textbf{J28}($\star\star$): \url{https://mathb.in/76055} (Manipolazioni di ED non lineari) \\
Soluzione del \textbf{J29}($\star\star$): \url{https://mathb.in/76052} (Metodo di Newton, un lemma sulla convessità)\\
Soluzione del \textbf{J30}($\star\star$): \url{https://mathb.in/76038} (Sommazione per parti e trucco di Van Der Corput)\\
Soluzione del \textbf{J31}($\star\star$): \url{https://mathb.in/76037} (Disuguaglianza di Jensen in forma integrale)\\
Soluzione del \textbf{J32}($\star\star\star$): \url{https://mathb.in/76053} (Formule di Viète e Newton, formula di inversione di M\"obius)  \\
Soluzione del \textbf{J33}($\star$): \url{https://mathb.in/76058} (Integrale di Dirichlet)\\
Soluzione del \textbf{J34}($\star\star\star$): \href{https://math.stackexchange.com/questions/2442091/a-ramanujan-sum/2442175#2442175}{Si veda StackExchange} (Trasformata di Laplace e numerose manipolazioni)\\
Soluzione del \textbf{J35}($\star$): \url{https://mathb.in/76050} \\
Soluzione del \textbf{J36}($\star$): \url{https://mathb.in/76036} (Azione dell'operatore $xD$ sulle OGF)\\
Soluzione del \textbf{J37}($\star$): \url{https://mathb.in/76070}\\
Soluzione del \textbf{J38}($\star$): \url{https://mathb.in/76071}\\
Soluzione del \textbf{J39}($\star$): \url{https://mathb.in/76072}\\
Soluzione del \textbf{J40}($\star\star$): \url{https://mathb.in/76073} (Disuguaglianza di Hoeffding)\\
Soluzione del \textbf{J41}($\star$): \url{https://mathb.in/76074}\\
Soluzione del \textbf{J42}($\star$): \url{https://mathb.in/76075} (Prodotto di Weierstrass del coseno)\\
Soluzione del \textbf{J43}($\star$): \url{https://mathb.in/76076}\\
Soluzione del \textbf{J44}($\star\star$): \url{https://mathb.in/76078} (Teorema di Banach-Caccioppoli)\\
Soluzione del \textbf{J45}($\star\star$): \url{https://mathb.in/76083} (Rappresentazioni integrali, stime di momenti)\\
Soluzione del \textbf{J46}($\star$): \url{https://mathb.in/76120} (Criterio di Abel-Dirichlet)\\
Soluzione del \textbf{J47}($\star$): \url{https://mathb.in/76090} (OGF dei binomiali centrali normalizzati)\\
Soluzione del \textbf{J48}($\star$): \url{https://mathb.in/76091} (Moltiplicazione di OGF)\\
Soluzione del \textbf{J49}($\star\star$): \url{https://mathb.in/76092} (Banach-Caccioppoli, sostituzioni) \\
Soluzione del \textbf{J50}($\star$): \url{https://mathb.in/76093} \\
Soluzione del \textbf{J51}($\star\star$): \url{https://mathb.in/76088} (Sostituzioni, integrali della forma $\int_{0}^{1}x^a(1-x)^b\,dx$, serie $\sum_{n\geq 1}\frac{\sin(nx)}{n}$)\\
Soluzione del \textbf{J52}($\star$): \url{https://mathb.in/76094} (Accenno agli integrali di Beukers)\\
Soluzione del \textbf{J53}($\star$): \url{https://mathb.in/76113} \\
Soluzione del \textbf{J54}($\star\star$): \url{https://mathb.in/76121} (Disuguaglianza tra le medie, coordinate sferiche)\\
Soluzione del \textbf{J55}($\star\star$): \url{https://mathb.in/76131} \\
Soluzione del \textbf{J56}($\star\star$): \url{https://mathb.in/76141}  (Convessità, Ceva)\\
Soluzione del \textbf{J57}($\star\star$): \url{https://mathb.in/76142}  (AM-GM)\\
Soluzione del \textbf{J58}($\star\star$): \url{https://mathb.in/76143}  (Metodo di Newton)\\
Soluzione del \textbf{J59}($\star$): \url{https://mathb.in/76133} \\
Soluzione del \textbf{J60}($\star\star$): \url{https://mathb.in/76144} (Lemmi di Archimede sulla parabola)\\
Soluzione del \textbf{J61}($\star\star$): \url{https://mathb.in/76145} \\
Soluzione del \textbf{J62}($\star$): \url{https://mathb.in/76134} \\
Soluzione del \textbf{J63}($\star$): \url{https://mathb.in/76146} \\
Soluzione del \textbf{J64}($\star$): \url{https://mathb.in/76151} (Principio del massimo modulo, Hales-Jewett)\\
Soluzione del \textbf{J65}($\star$): \url{https://mathb.in/76135} \\
Soluzione del \textbf{J66}($\star\star$): \url{https://mathb.in/76132} (Prodotto di Eulero, problema di Basilea)\\
Soluzione del \textbf{J67}($\star$): \url{https://mathb.in/76147} (Sommazione per parti ripetuta)\\
Soluzione del \textbf{J68}($\star\star$): \url{https://mathb.in/76152} (Diversi trucchi trigonometrici, Maclaurin di $x\cot x$)\\
Soluzione del \textbf{J69}($\star\star$): \url{https://mathb.in/76156} (Formula di Cramer, prodotti scalari, polinomi di Legendre)\\

\newpage
\section{Appendice}
In questa parte sono presenti collegamenti a brevi schede di approfondimento, e qualche riferimento bibliografico.

\subsection{Schede di approfondimento}


Concetto di \textbf{area} - \url{https://mathb.in/76086}

Formule di \textbf{Viète} - \url{https://mathb.in/75995}

\textbf{Somme di potenze consecutive} via HSI o stars\&bars - \url{https://mathb.in/75975}

\textbf{Esponenziale} e dintorni - \url{https://mathb.in/75935}

\textbf{Limiti notevoli} - \url{https://mathb.in/75954}

\textbf{Criteri di convergenza per serie}, in breve - \url{https://mathb.in/75938}

\textbf{EGZ} e \textbf{BW} - \url{https://mathb.in/75922}

Elementi di topologia, \textbf{Compattezza} e \textbf{HC} - \url{https://mathb.in/75930}

Tips\&Tricks per l'\textbf{integrazione di funzioni razionali} - \url{https://mathb.in/75931}

Disuguaglianza di \textbf{Hermite-Hadamard} - \url{https://mathb.in/76138}

\textbf{Teorema di approssimazione di Weierstrass} - \href{https://drive.google.com/file/d/1QKCejQNSohMTlZs-MPRndxo5tJ8H48Ez/view?usp=sharing}{Note di Jack} , pagina 115

\textbf{Teoremi di punto fisso} (Banach e Banach-Caccioppoli) - \url{https://mathb.in/75936}

\textbf{Illimitatezza e impropria Riemann-integrabilità} - \url{https://mathb.in/76177}

Formula di \textbf{Taylor con resto integrale} - \href{https://www2.math.upenn.edu/~kazdan/361F15/Notes/Taylor-integral.pdf}{Appunto di Kazdan}

\textbf{Integrali delle potenze del (co)seno} - \url{https://mathb.in/75993}

\textbf{Binomiali centrali e momenti} - \url{https://mathb.in/75947}

\textbf{Prodotti di Wallis, Weierstrass ed Eulero} - \url{https://mathb.in/75959}

\textbf{Approssimazione di Stirling} - \url{https://mathb.in/75976}


\subsection{Riferimenti bibliografici}

Per la preparazione teorica consigliamo i testi
\begin{itemize}
 \item \emph{Primo corso di Analisi Matematica} di Emilio Acerbi e Giuseppe Buttazzo. Ha una prima parte introduttiva molto \emph{reader friendly}, è molto rigoroso nella trattazione ed è ricco di appendici estremamente interessanti.
 \item \emph{Analisi matematica, Teoria ed applicazioni} di Acquistapace, Conti e Savojni. Testo di rara eleganza, ha un'impostazione squisitamente geometrica che è un peccato perdersi. \emph{Achtung}: sconfina rapidamente nell'Analisi in più variabili e nella geometria differenziale.
\end{itemize}

Per quanto concerne gli esercizi consigliamo, oltre ai $69$ sovrastanti, 
\begin{itemize}
 \item \href{https://pagine.dm.unipi.it/gobbino/Home_Page/Files/HP_AD/Eserciziari/AM1_Esercizi.pdf}{Esercizi di Analisi Matematica 1} di Marina Ghisi e Massimo Gobbino. Vasto assortimento di esercizi di medio o medio-basso livello, con qualche sconfinamento in esercizi impegnativi (riguardo successioni per ricorrenza o comportamenti qualitativi di soluzioni di equazioni differenziali, ad esempio). Un \emph{must} per farsi le ossa.
 \item \emph{Problemi scelti di Analisi Matematica 1} di Acerbi, Modica e Spagnolo. Campionario più breve del precedente, ma decisamente più impegnativo. Consigliatissimo a chi sente di avere già acquisito una solida preparazione sui fondamentali.
 
\end{itemize}



\end{document}


